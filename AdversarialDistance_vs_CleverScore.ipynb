{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Installation of Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yI06pkYh_4fl"
   },
   "outputs": [],
   "source": [
    "!pip install cleverhans --quiet\n",
    "!pip install adversarial-robustness-toolbox --quiet\n",
    "!pip install multiprocess --quiet\n",
    "!pip install importlib --quiet\n",
    "!pip install advertorch --quiet\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --quiet\n",
    "!pip install git+https://github.com/RobustBench/robustbench.git\n",
    "!git clone https://github.com/Georgsiedel/adversarial-distance-estimation.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries for Adversarial Robustness and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaAo9r_3AHfq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import numba\n",
    "numba.__version__\n",
    "\n",
    "import importlib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.metrics import clever_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Device for Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Load and Truncate the CIFAR-10 Dataset for Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWrb8lalAKj2"
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataset_split):\n",
    "    # Load CIFAR-10 dataset using torchvision\n",
    "    transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "                                 ])\n",
    "    testset = datasets.CIFAR10(root='./data/cifar', train=False, download=True, transform=transform)\n",
    "\n",
    "    # Truncated testset for experiments and ablations\n",
    "    if isinstance(dataset_split, int):\n",
    "        testset, _ = torch.utils.data.random_split(testset,\n",
    "                                                          [dataset_split, len(testset) - dataset_split],\n",
    "                                                          generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    # Extract data and labels from torchvision dataset\n",
    "    xtest = torch.stack([data[0] for data in testset])\n",
    "    ytest = torch.tensor([data[1] for data in testset])\n",
    "\n",
    "    return xtest, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Test Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, xtest, ytest):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(xtest)):\n",
    "            x = xtest[i].unsqueeze(0).to(device)\n",
    "            y = ytest[i].unsqueeze(0).to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += y.size(0)\n",
    "            correct += (predicted==y).sum().item()\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f'\\nAccuracy of the testset is: {accuracy:.3f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Initializing Different Types of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWzlhwRgAMls"
   },
   "outputs": [],
   "source": [
    "#%cd /kaggle/working/adversarial-distance-estimation\n",
    "import models.wideresnet as wideresnet\n",
    "from robustbench.utils import load_model\n",
    "\n",
    "modeltype = 'adversarial'\n",
    "\n",
    "print(f'\\nLoading {modeltype} Model...\\n')\n",
    "if modeltype == 'standard':\n",
    "    net = wideresnet.WideResNet_28_4(10, 'CIFAR10', normalized=True, block=wideresnet.WideBasic, activation_function='relu')\n",
    "    state_dict = \"model_state_dict\"\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    PATH = f'./models/pretrained_models/{modeltype}.pth'\n",
    "    model = torch.load(PATH)\n",
    "    net.load_state_dict(model[state_dict], strict=False)\n",
    "elif modeltype == 'robust':\n",
    "    #self trained with massive random data augmentation and JSD consistency loss, but no adversarial objective\n",
    "    net = wideresnet.WideResNet_28_4(10, 'CIFAR10', normalized=True, block=wideresnet.WideBasic, activation_function='silu')\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    state_dict = \"model_state_dict\"\n",
    "    PATH = f'./models/pretrained_models/{modeltype}.pth'\n",
    "    model = torch.load(PATH)\n",
    "    net.load_state_dict(model[state_dict], strict=False)\n",
    "elif modeltype == 'adversarial':\n",
    "    #from https://github.com/BorealisAI/mma_training/tree/master/trained_models/cifar10-Linf-MMA-20-sd0\n",
    "    model_name = 'Ding2020MMA'\n",
    "    net = load_model(model_name=model_name, dataset='cifar10', threat_model='Linf')\n",
    "    net = torch.nn.DataParallel(net)\n",
    "\n",
    "%cd\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t9UUJ1QM0889"
   },
   "outputs": [],
   "source": [
    "#criterion and optimizer do not matter for the evaluation-only in this notebook\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "classifier = PyTorchClassifier(model=net,\n",
    "                               loss=criterion,\n",
    "                               optimizer=optimizer,\n",
    "                               input_shape=(3, 32, 32),\n",
    "                               nb_classes=10,\n",
    "                              device_type=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Evasion Attack Methods from the ART Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWBxh1Ko0889"
   },
   "outputs": [],
   "source": [
    "from art.attacks.evasion import (FastGradientMethod,\n",
    "                                 ProjectedGradientDescentNumpy,\n",
    "                                 AutoAttack,\n",
    "                                 AutoProjectedGradientDescent,\n",
    "                                 AutoConjugateGradient,\n",
    "                                 CarliniLInfMethod,\n",
    "                                 CarliniL2Method,\n",
    "                                 NewtonFool,\n",
    "                                 DeepFool,\n",
    "                                 ElasticNet,\n",
    "                                 FrameSaliencyAttack,\n",
    "                                 HopSkipJump,\n",
    "                                 BasicIterativeMethod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cyvfen8L0889"
   },
   "source": [
    "## Adversarial Attack Initialization Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwPM_HK1088-"
   },
   "outputs": [],
   "source": [
    "class AdversarialAttacks:\n",
    "  def __init__(self, classifier, epsilon, eps_iter, norm, iterations, second_attack_iters):\n",
    "    self.classifier = classifier\n",
    "    self.epsilon = epsilon\n",
    "    self.eps_iter = eps_iter\n",
    "    self.norm = norm\n",
    "    self.iterations = iterations\n",
    "    self.second_attack_iters = second_attack_iters\n",
    "\n",
    "  def init_attacker(self, attack_type, **kwargs):\n",
    "    if attack_type=='fast_gradient_method':\n",
    "        return FastGradientMethod(self.classifier,\n",
    "                                eps=self.epsilon,\n",
    "                                eps_step=self.eps_iter,\n",
    "                                minimal=True,\n",
    "                                norm=self.norm,\n",
    "                                **kwargs)\n",
    "    elif attack_type=='projected_gradient_descent':\n",
    "        return ProjectedGradientDescentNumpy(self.classifier,\n",
    "                                             eps=self.epsilon,\n",
    "                                             eps_step=self.eps_iter,\n",
    "                                             max_iter=self.iterations,\n",
    "                                             norm=self.norm,\n",
    "                                             **kwargs)\n",
    "    elif attack_type=='auto_attack':\n",
    "        return AutoAttack(estimator=self.classifier,\n",
    "                        eps=self.epsilon,\n",
    "                        eps_step=self.eps_iter,\n",
    "                        norm=self.norm)\n",
    "    elif attack_type=='auto_projected_gradient_descent':\n",
    "        return AutoProjectedGradientDescent(estimator=self.classifier,\n",
    "                                          eps=self.epsilon,\n",
    "                                          eps_step=self.eps_iter,\n",
    "                                          norm=self.norm,\n",
    "                                          max_iter=self.iterations,\n",
    "                                          **kwargs)\n",
    "    elif attack_type=='auto_conjugate_gradient':\n",
    "        return AutoConjugateGradient(estimator=self.classifier,\n",
    "                                   eps=self.epsilon,\n",
    "                                   eps_step=self.eps_iter,\n",
    "                                   norm=self.norm,\n",
    "                                   max_iter=self.iterations,\n",
    "                                   **kwargs)\n",
    "    elif attack_type=='carlini_wagner_linf':\n",
    "        return CarliniLInfMethod(self.classifier,\n",
    "                               max_iter=self.second_attack_iters,\n",
    "                               **kwargs)\n",
    "    elif attack_type=='carlini_wagner_l2':\n",
    "        return CarliniL2Method(self.classifier,\n",
    "                               max_iter=self.second_attack_iters,\n",
    "                               **kwargs)\n",
    "    elif attack_type=='newton_fool':\n",
    "        return NewtonFool(self.classifier,\n",
    "                        max_iter=self.iterations,\n",
    "                        **kwargs)\n",
    "    elif attack_type=='deep_fool':\n",
    "        return DeepFool(self.classifier,\n",
    "                      max_iter=self.iterations,\n",
    "                      epsilon=self.eps_iter,\n",
    "                      **kwargs)\n",
    "    elif attack_type=='elastic_net':\n",
    "        return ElasticNet(self.classifier,\n",
    "                      max_iter=self.second_attack_iters)\n",
    "    elif attack_type=='frame_saliency':\n",
    "        attacker = BasicIterativeMethod(self.classifier,\n",
    "                                                 eps=self.epsilon,\n",
    "                                                 eps_step=self.eps_iter,\n",
    "                                                 max_iter=self.iterations,\n",
    "                                      )\n",
    "        return FrameSaliencyAttack(self.classifier,\n",
    "                                 attacker,\n",
    "                                 method='iterative_saliency')\n",
    "    elif attack_type=='hop_skip_jump':\n",
    "        return HopSkipJump(self.classifier,\n",
    "                         norm=self.norm,\n",
    "                         max_iter=self.second_attack_iters)\n",
    "    else:\n",
    "        raise ValueError(f'Attack type \"{attack_type}\" not supported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uRV8mgQ088-"
   },
   "source": [
    "## Plug-in Function for Adversarial Attack with Early Stopping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOEoobVl088-"
   },
   "outputs": [],
   "source": [
    "def attack_with_early_stopping(classifier, x, y, max_iterations, attacker):\n",
    "    label_flipped = False\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    x = x.unsqueeze(0)\n",
    "\n",
    "    outputs = classifier.predict(x.cpu().numpy())\n",
    "    _, clean_predicted = torch.max(torch.tensor(outputs).to(device).data, 1)\n",
    "\n",
    "    if int(clean_predicted.item()) != int(y.item()):\n",
    "        print('Misclassified input. Not attacking.')\n",
    "        end_time = time.time()\n",
    "        return x.cpu().detach().numpy(), end_time - start_time, 0\n",
    "\n",
    "    for j in range(max_iterations):\n",
    "        adv_inputs = attacker.generate(x.cpu().detach().numpy(), y.cpu().detach().numpy())\n",
    "\n",
    "        adv_inputs_tensor = torch.from_numpy(adv_inputs).to(device)\n",
    "        outputs = classifier.predict(adv_inputs)\n",
    "        _, predicted = torch.max(torch.tensor(outputs).to(device).data, 1)\n",
    "\n",
    "        label_flipped = bool(predicted.item() != int(y.item()))\n",
    "\n",
    "        if label_flipped:\n",
    "            print(f'\\tIterations for successful iterative attack: {j+1}')\n",
    "            break\n",
    "            \n",
    "        x = adv_inputs_tensor.clone()\n",
    "\n",
    "    end_time = time.time()\n",
    "    return adv_inputs, end_time - start_time, j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGxN0Bf7088-"
   },
   "source": [
    "## CLEVER Score Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLpPkx0L088-"
   },
   "outputs": [],
   "source": [
    "def clever_score_calculation(classifier, xtest, max_epsilon, nb_batch, batch_size, norm):\n",
    "  # Calculate CLEVER score\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "  # Convert the reshaped tensor to a numpy array\n",
    "  xtest_np = xtest.cpu().numpy()\n",
    "\n",
    "  # Initialize lists to store CLEVER scores and corresponding image IDs\n",
    "  images_id, clever_scores, runtimes = [], [], []\n",
    "\n",
    "  # Iterate through each image for CLEVER score calculation\n",
    "  for image in range(len(xtest)):\n",
    "    start_time = time.time()\n",
    "    # Calculate CLEVER score using the provided classifier and parameters\n",
    "    clever_score = clever_u(classifier,\n",
    "                              x=xtest_np[image],\n",
    "                              nb_batches=nb_batch,\n",
    "                              batch_size=batch_size,\n",
    "                              radius=max_epsilon,\n",
    "                              norm=norm,\n",
    "                              pool_factor=3)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Append the calculated CLEVER score to the list\n",
    "    clever_scores.append(clever_score)\n",
    "\n",
    "    # Append the image ID to the list\n",
    "    images_id.append(image)\n",
    "\n",
    "    # Append runtime for each image\n",
    "    runtimes.append(elapsed_time)\n",
    "\n",
    "    # Print the calculated CLEVER score for the current image\n",
    "    print(f\"Image: {image}, Score: {clever_score}, Runtime: {elapsed_time} sec\")\n",
    "\n",
    "  results_dict = {\n",
    "      'images_id': images_id,\n",
    "      'clever_score': clever_scores,\n",
    "      'runtime': runtimes}\n",
    "  print(f'\\nTotal runtime for {len(xtest)} images is {np.sum(results_dict[\"runtime\"])} seconds\\n')\n",
    "  return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Adversarial Distance and CLEVER Score Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zryQDu0088-"
   },
   "outputs": [],
   "source": [
    "def combined_adv_dist_clever_score(classifier, xtest, ytest, epsilon, eps_iter, norm, max_iterations, clever_configs: list, get_image: bool = False, verbose: bool = False):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    classifier.model.to(device)\n",
    "    xtest = xtest.to(device)\n",
    "    ytest = ytest.to(device)\n",
    "\n",
    "    minimum_adversarial_distance = []\n",
    "    results_dict = {f'{norm}': {\n",
    "            'clever_score': {},\n",
    "            'adversarial_distance_pgd': [],\n",
    "            'iterations_pgd': [],\n",
    "            'adversarial_distance_second_attack': [],\n",
    "            'indices': [],\n",
    "            'max_adversarial_distance': 0.0\n",
    "        }\n",
    "    }\n",
    "\n",
    "    attacks = AdversarialAttacks(classifier=classifier,\n",
    "                                 epsilon=epsilon,\n",
    "                                 eps_iter=eps_iter,\n",
    "                                 norm=norm,\n",
    "                                 iterations=1,\n",
    "                                 second_attack_iters=100)\n",
    "\n",
    "    iterative_attack_type = 'projected_gradient_descent'\n",
    "    attacker1 = attacks.init_attacker(iterative_attack_type, verbose=verbose)\n",
    "\n",
    "    if norm == 1:\n",
    "        second_attack_type = 'elastic_net'\n",
    "    elif norm == 2:\n",
    "        second_attack_type = 'carlini_wagner_l2'\n",
    "    else:\n",
    "        second_attack_type = 'hop_skip_jump'\n",
    "    attacker_2 = attacks.init_attacker(second_attack_type)\n",
    "\n",
    "    correct_prediction_1, correct_prediction_2 = 0, 0\n",
    "\n",
    "    for i, x in enumerate(xtest):\n",
    "        x = x.to(device)\n",
    "        y = ytest[i].unsqueeze(0).to(device)\n",
    "\n",
    "        # First Attack\n",
    "        print(f'\\nAttacking image {i}\\n\\t-with {iterative_attack_type}')\n",
    "        x_adversarial_1, runtime_1, j = attack_with_early_stopping(classifier=classifier,\n",
    "                                                                x=x,\n",
    "                                                                y=y,\n",
    "                                                                max_iterations=max_iterations,\n",
    "                                                                attacker=attacker1)\n",
    "\n",
    "        x_adversarial_tensor = torch.from_numpy(x_adversarial_1).to(device)\n",
    "\n",
    "        # Adversarial accuracy calculation\n",
    "        output_adversarial_1 = classifier.predict(x_adversarial_1)\n",
    "        _, predicted_adversarial_1 = torch.max(torch.tensor(output_adversarial_1).to(device).data, 1)\n",
    "        correct_prediction_1 += (predicted_adversarial_1.item() == int(y.item()))\n",
    "\n",
    "        distance_1 = torch.norm((x - x_adversarial_tensor), p=float(norm))\n",
    "        results_dict[f'{norm}']['adversarial_distance_pgd'].append(distance_1.item())\n",
    "        results_dict[f'{norm}']['iterations_pgd'].append(j)\n",
    "\n",
    "        # Second Attack\n",
    "        x = x.unsqueeze(0)\n",
    "        outputs = classifier.predict(x.cpu().numpy())\n",
    "        _, clean_predicted = torch.max(torch.tensor(outputs).to(device).data, 1)\n",
    "\n",
    "        if int(clean_predicted.item()) == int(y.item()):\n",
    "            \n",
    "            print(f'\\t-with {second_attack_type}\\n')\n",
    "            time1 = time.time()\n",
    "            x_adversarial_2 = attacker_2.generate(x=x.cpu().numpy(),\n",
    "                                                  y=np.expand_dims(y.cpu().numpy(), axis=0))\n",
    "            time2 = time.time()\n",
    "            runtime_2 = time2 - time1\n",
    "\n",
    "            x_adversarial_tensor = torch.tensor(x_adversarial_2).to(device)\n",
    "        \n",
    "        else:\n",
    "            x_adversarial_2 = x.cpu().numpy()\n",
    "            runtime_2 = 0.0\n",
    "            x_adversarial_tensor = x.to(device)\n",
    "\n",
    "        # Adversarial accuracy calculation\n",
    "        output_adversarial_2 = classifier.predict(x_adversarial_2)\n",
    "        _, predicted_adversarial_2 = torch.max(torch.tensor(output_adversarial_2).to(device).data, 1)\n",
    "        correct_prediction_2 += (predicted_adversarial_2.item() == int(y.item()))\n",
    "\n",
    "        distance_2 = torch.norm((x - x_adversarial_tensor), p=float(norm))\n",
    "        results_dict[f'{norm}']['adversarial_distance_second_attack'].append(distance_2.item())\n",
    "        \n",
    "        print(f'distance1: {distance_1.item():.4f}\\tdistance2: {distance_2.item():.4f}\\timage index: {i}')\n",
    "        results_dict[f'{norm}']['indices'].append(i)\n",
    "        \n",
    "        if j<(max_iterations - 1):\n",
    "            if distance_2>0.0:\n",
    "                minimum_adversarial_distance.append(min(distance_1.item(), distance_2.item()))\n",
    "            else:\n",
    "                minimum_adversarial_distance.append(distance_1.item())\n",
    "        else:\n",
    "            if distance_2>0.0:\n",
    "                minimum_adversarial_distance.append(distance_2.item())\n",
    "            \n",
    "\n",
    "    adversarial_accuracy_1 = (correct_prediction_1 / len(xtest)) * 100\n",
    "    adversarial_accuracy_2 = (correct_prediction_2 / len(xtest)) * 100\n",
    "    print(f'Adversarial accuracy of {adversarial_accuracy_1}  (iterative attack) {adversarial_accuracy_2} (second attack).'\n",
    "          'If the lower values is not close to 0, increase attack strength for accurate adversarial distance estimation!')\n",
    "    \n",
    "    # Clever Score Calculation\n",
    "    max_adv_dist = max(minimum_adversarial_distance)\n",
    "    results_dict[f'{norm}']['max_adversarial_distance'] = max_adv_dist\n",
    "    print(f'\\nmin list: {minimum_adversarial_distance}\\n')\n",
    "    print(f'\\nClever calculation will be done with maximum adversarial distance: {max_adv_dist}\\n')\n",
    "\n",
    "    clever_configs_results = {}\n",
    "    for nb_batch, batch_size in clever_configs:\n",
    "        print(f'Config: [{nb_batch}, {batch_size}]')\n",
    "        results_dict_clever = clever_score_calculation(classifier=classifier,\n",
    "                                                       xtest=xtest,\n",
    "                                                       max_epsilon=max_adv_dist,\n",
    "                                                       nb_batch=nb_batch,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       norm=norm)\n",
    "        clever_configs_results[f'{nb_batch}-{batch_size}'] = results_dict_clever\n",
    "\n",
    "        results_dict[f'{norm}']['clever_score'][f'{nb_batch}-{batch_size}'] = np.array(results_dict_clever['clever_score']).tolist()\n",
    "\n",
    "    return results_dict, max_adv_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttoH3TiR088-"
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJsDNRDH088_"
   },
   "outputs": [],
   "source": [
    "norm = 2\n",
    "max_iterations = 500\n",
    "eps_iter_dict = {\n",
    "    'inf': 0.0003,\n",
    "    '1': 0.2,\n",
    "    '2': 0.005}\n",
    "eps_iter = eps_iter_dict[str(norm)]\n",
    "epsilon = max_iterations * eps_iter\n",
    "\n",
    "clever_configs = [(5, 5), \n",
    "                  (10, 20),\n",
    "                  (50, 100), \n",
    "                  (500, 1024)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzlvSLFr088_"
   },
   "outputs": [],
   "source": [
    "splitsize = 500        # full, int: splitsize\n",
    "xtest, ytest = load_dataset(dataset_split=splitsize)\n",
    "xtest, ytest = xtest.to(device), ytest.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy(model=net,\n",
    "             xtest=xtest,\n",
    "             ytest=ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Distance and Clever Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_EGILjH088_"
   },
   "outputs": [],
   "source": [
    "results_dict, max_adversarial_distance = combined_adv_dist_clever_score(classifier,\n",
    "                                                   xtest=xtest,\n",
    "                                                   ytest=ytest,\n",
    "                                                   epsilon=epsilon,\n",
    "                                                   eps_iter=eps_iter,\n",
    "                                                   norm=norm,\n",
    "                                                   max_iterations=max_iterations,\n",
    "                                                    clever_configs=clever_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Adversarial Distances and Calculating Minimum Attack Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_batch, batch_size = clever_configs[-1][0], clever_configs[-1][1]\n",
    "clever_values = results_dict[f'{norm}']['clever_score'][f'{nb_batch}-{batch_size}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_attack_value, colors_attack, colors_clever = [], [], []\n",
    "\n",
    "for i in range(len(results_dict[f\"{norm}\"]['adversarial_distance_pgd'])):\n",
    "    \n",
    "    #Misclassified inputs\n",
    "    if results_dict[f\"{norm}\"]['adversarial_distance_pgd'][i]==0.0:\n",
    "        colors_attack.append('blue')\n",
    "        colors_clever.append('black')\n",
    "        clever_values[i] = None\n",
    "        min_attack_value.append(0.0)\n",
    "        \n",
    "    # Both attacks unsuccessful\n",
    "    elif modeltype=='adversarial' and results_dict[f\"{norm}\"]['iterations_pgd'][i] == (max_iterations - 1) and results_dict[f\"{norm}\"]['adversarial_distance_second_attack'][i] == 0.0:\n",
    "        colors_attack.append('blue')\n",
    "        colors_clever.append('black')\n",
    "        min_attack_value.append(max_adversarial_distance)\n",
    "    \n",
    "    # CW is None but PGD works\n",
    "    elif modeltype=='adversarial' and results_dict[f\"{norm}\"]['iterations_pgd'][i] < (max_iterations - 1) and results_dict[f\"{norm}\"]['adversarial_distance_second_attack'][i] == 0.0:\n",
    "        colors_attack.append('blue')\n",
    "        min_attack_value.append(results_dict[f\"{norm}\"]['adversarial_distance_pgd'][i])\n",
    "        if results_dict[f'{norm}']['clever_score'][f'{nb_batch}-{batch_size}'][i]>results_dict[f\"{norm}\"]['adversarial_distance_pgd'][i]:\n",
    "            colors_clever.append('red')\n",
    "        else:\n",
    "            colors_clever.append('black')\n",
    "    \n",
    "    # PGD is None but CW works\n",
    "    elif results_dict[f\"{norm}\"]['iterations_pgd'][i] == (max_iterations - 1) and results_dict[f\"{norm}\"]['adversarial_distance_second_attack'][i] > 0.0:\n",
    "        colors_attack.append('green')\n",
    "        min_attack_value.append(results_dict[f\"{norm}\"]['adversarial_distance_second_attack'][i])\n",
    "        if results_dict[f'{norm}']['clever_score'][f'{nb_batch}-{batch_size}'][i]>results_dict[f\"{norm}\"]['adversarial_distance_second_attack'][i]:\n",
    "            colors_clever.append('red')\n",
    "        else:\n",
    "            colors_clever.append('black')\n",
    "        \n",
    "    # take min of two\n",
    "    else:\n",
    "        if results_dict[f\"{norm}\"]['adversarial_distance_second_attack'][i]<results_dict[f\"{norm}\"]['adversarial_distance_pgd'][i]:\n",
    "            colors_attack.append('green')\n",
    "            min_attack_value.append(results_dict[f\"{norm}\"]['adversarial_distance_second_attack'][i])\n",
    "        else:    \n",
    "            colors_attack.append('blue')\n",
    "            min_attack_value.append(results_dict[f\"{norm}\"]['adversarial_distance_pgd'][i])\n",
    "        \n",
    "        if min_attack_value[i]>=results_dict[f'{norm}']['clever_score'][f'{nb_batch}-{batch_size}'][i]:\n",
    "            colors_clever.append('black')\n",
    "        else:\n",
    "            colors_clever.append('red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.argsort(min_attack_value)\n",
    "min_attack_value_sorted = np.array(min_attack_value)[sorted_indices].tolist()\n",
    "clever_values_sorted = np.array(clever_values)[sorted_indices].tolist()\n",
    "colors_attack_sorted = np.array(colors_attack)[sorted_indices].tolist()\n",
    "colors_clever_sorted = np.array(colors_clever)[sorted_indices].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqeyI_qq088_"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_file_path = f'/kaggle/working/adversarial-distance-estimation/data/adv_dist_vs_clever_{modeltype}_{norm}.json'\n",
    "\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(results_dict, f, sort_keys=True)\n",
    "print(f'Evaluation results are saved under \"{json_file_path}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "# Calculate the error proportion\n",
    "total_points = 0\n",
    "red_points = 0\n",
    "\n",
    "image_ids = np.arange(len(min_attack_value))\n",
    "\n",
    "for i in range(len(image_ids)):\n",
    "    if clever_values_sorted[i] is not None:\n",
    "        total_points += 1\n",
    "        if clever_values_sorted[i] > min_attack_value_sorted[i]:\n",
    "            red_points += 1\n",
    "\n",
    "error_proportion = (red_points / total_points) * 100 if total_points > 0 else 0\n",
    "\n",
    "mean_clever_score = np.mean([x for x in clever_values_sorted if x is not None and np.isnan(x)==False])\n",
    "mean_min_attack_value = np.mean([x for x in min_attack_value_sorted if np.isnan(x)==False])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(image_ids, min_attack_value_sorted, color=colors_attack_sorted)\n",
    "plt.scatter(image_ids, clever_values_sorted, color=colors_clever_sorted)\n",
    "# Adding labels and title with error proportion\n",
    "plt.xlabel('Image ID')\n",
    "plt.ylabel(f'L{norm} Distance')\n",
    "plt.title(f'Error Proportion: {error_proportion:.2f}%   Mean Clever Score: {mean_clever_score:.4f}   Mean Adversarial Distance: {mean_min_attack_value:.4f}', fontsize=14)\n",
    "plt.xticks(np.arange(0, len(sorted_indices), 10))\n",
    "# Avoid label duplication in the legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "\n",
    "legend_elements = [\n",
    "    mlines.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', label='Adversarial Distance (PGD)'),\n",
    "    mlines.Line2D([0], [0], marker='o', color='w', markerfacecolor='green', label='Adversarial Distance (Second attack)'),\n",
    "    mlines.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', label='Clever Score $\\geq$ Adversarial DWistance'),\n",
    "    mlines.Line2D([0], [0], marker='o', color='w', markerfacecolor='black', label='Clever Score $<$ Adversarial Distance')\n",
    "]\n",
    "\n",
    "plt.legend(handles=legend_elements, fontsize=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
