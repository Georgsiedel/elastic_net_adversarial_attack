{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation and Repository cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (6.29.5)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipykernel) (1.8.9)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipykernel) (8.29.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipykernel) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipykernel) (6.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipykernel) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipykernel) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (308)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Collecting adversarial-robustness-toolbox\n",
      "  Using cached adversarial_robustness_toolbox-1.18.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting numpy>=1.18.0 (from adversarial-robustness-toolbox)\n",
      "  Using cached numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scipy>=1.4.1 (from adversarial-robustness-toolbox)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn>=0.22.2 (from adversarial-robustness-toolbox)\n",
      "  Using cached scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from adversarial-robustness-toolbox) (1.16.0)\n",
      "Collecting setuptools (from adversarial-robustness-toolbox)\n",
      "  Using cached setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting tqdm (from adversarial-robustness-toolbox)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=0.22.2->adversarial-robustness-toolbox)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.22.2->adversarial-robustness-toolbox)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\georg siedel\\documents\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from tqdm->adversarial-robustness-toolbox) (0.4.6)\n",
      "Using cached adversarial_robustness_toolbox-1.18.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "Using cached setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: tqdm, threadpoolctl, setuptools, numpy, joblib, scipy, scikit-learn, adversarial-robustness-toolbox\n",
      "Successfully installed adversarial-robustness-toolbox-1.18.2 joblib-1.4.2 numpy-2.1.3 scikit-learn-1.5.2 scipy-1.14.1 setuptools-75.6.0 threadpoolctl-3.5.0 tqdm-4.67.1\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting dill>=0.3.9 (from multiprocess)\n",
      "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Using cached multiprocess-0.70.17-py312-none-any.whl (147 kB)\n",
      "Using cached dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Installing collected packages: dill, multiprocess\n",
      "Successfully installed dill-0.3.9 multiprocess-0.70.17\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: zipp, importlib-metadata\n",
      "Successfully installed importlib-metadata-8.5.0 zipp-3.21.0\n",
      "Collecting advertorch\n",
      "  Using cached advertorch-0.2.3-py3-none-any.whl\n",
      "Installing collected packages: advertorch\n",
      "Successfully installed advertorch-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install adversarial-robustness-toolbox -U\n",
    "!pip install multiprocess\n",
    "!pip install importlib-metadata\n",
    "!pip install advertorch\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install git+https://github.com/RobustBench/robustbench.git\n",
    "!pip install numba\n",
    "!pip install matplotlib\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import numba\n",
    "numba.__version__\n",
    "\n",
    "import importlib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageOps\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_split):\n",
    "    # Load CIFAR-10 dataset using torchvision\n",
    "    transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "                                 ])\n",
    "    testset = datasets.CIFAR10(root='./data/cifar', train=False, download=True, transform=transform)\n",
    "\n",
    "    # Truncated testset for experiments and ablations\n",
    "    if isinstance(dataset_split, int):\n",
    "        testset, _ = torch.utils.data.random_split(testset,\n",
    "                                                          [dataset_split, len(testset) - dataset_split],\n",
    "                                                          generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    # Extract data and labels from torchvision dataset\n",
    "    xtest = torch.stack([data[0] for data in testset])\n",
    "    ytest = torch.tensor([data[1] for data in testset])\n",
    "\n",
    "    return xtest, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare WideResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /kaggle/working/adversarial-distance-estimation\n",
    "import models.wideresnet as wideresnet\n",
    "from robustbench.utils import load_model\n",
    "\n",
    "modeltype = 'adversarial'\n",
    "\n",
    "print(f'\\nLoading {modeltype} Model...\\n')\n",
    "if modeltype == 'standard':\n",
    "    net = wideresnet.WideResNet_28_4(10, 'CIFAR10', normalized=True, block=wideresnet.WideBasic, activation_function='relu')\n",
    "    state_dict = \"model_state_dict\"\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    PATH = f'./models/pretrained_models/{modeltype}.pth'\n",
    "    model = torch.load(PATH)\n",
    "    net.load_state_dict(model[state_dict], strict=False)\n",
    "elif modeltype == 'robust':\n",
    "    #self trained with massive random data augmentation and JSD consistency loss, but no adversarial objective\n",
    "    net = wideresnet.WideResNet_28_4(10, 'CIFAR10', normalized=True, block=wideresnet.WideBasic, activation_function='silu')\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    state_dict = \"model_state_dict\"\n",
    "    PATH = f'./models/pretrained_models/{modeltype}.pth'\n",
    "    model = torch.load(PATH)\n",
    "    net.load_state_dict(model[state_dict], strict=False)\n",
    "elif modeltype == 'adversarial':\n",
    "    #from https://github.com/BorealisAI/mma_training/tree/master/trained_models/cifar10-Linf-MMA-20-sd0\n",
    "    model_name = 'Ding2020MMA'\n",
    "    net = load_model(model_name=model_name, dataset='cifar10', threat_model='Linf')\n",
    "    net = torch.nn.DataParallel(net)\n",
    "\n",
    "%cd\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Test Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, xtest, ytest):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(xtest)):\n",
    "            x = xtest[i].unsqueeze(0).to(device)\n",
    "            y = ytest[i].unsqueeze(0).to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += y.size(0)\n",
    "            correct += (predicted==y).sum().item()\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f'\\nAccuracy of the testset is: {accuracy:.3f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# Initialize PyTorchClassifier for ART\n",
    "classifier = PyTorchClassifier(model=net,\n",
    "                               loss=criterion,\n",
    "                               optimizer=optimizer,\n",
    "                               input_shape=(3, 32, 32),\n",
    "                               nb_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import (FastGradientMethod,\n",
    "                                 ProjectedGradientDescentNumpy,\n",
    "                                 AutoAttack,\n",
    "                                 AutoProjectedGradientDescent,\n",
    "                                 CarliniL2Method,\n",
    "                                 NewtonFool,\n",
    "                                 DeepFool,\n",
    "                                 ElasticNet,\n",
    "                                 HopSkipJump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Attack Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialAttacks:\n",
    "  def __init__(self, classifier, epsilon, eps_iter, norm, iterations, second_attack_iters):\n",
    "    self.classifier = classifier\n",
    "    self.epsilon = epsilon\n",
    "    self.eps_iter = eps_iter\n",
    "    self.norm = norm\n",
    "    self.iterations = iterations\n",
    "    self.second_attack_iters = second_attack_iters\n",
    "\n",
    "  def init_attacker(self, attack_type, **kwargs):\n",
    "    if attack_type=='fast_gradient_method':\n",
    "        return FastGradientMethod(self.classifier,\n",
    "                                eps=self.epsilon,\n",
    "                                eps_step=self.eps_iter,\n",
    "                                minimal=True,\n",
    "                                norm=self.norm,\n",
    "                                **kwargs)\n",
    "    elif attack_type=='projected_gradient_descent':\n",
    "        return ProjectedGradientDescentNumpy(self.classifier,\n",
    "                                             eps=self.epsilon,\n",
    "                                             eps_step=self.eps_iter,\n",
    "                                             max_iter=self.iterations,\n",
    "                                             norm=self.norm,\n",
    "                                             **kwargs)\n",
    "    elif attack_type=='auto_attack':\n",
    "        return AutoAttack(estimator=self.classifier,\n",
    "                        eps=self.epsilon,\n",
    "                        eps_step=self.eps_iter,\n",
    "                        norm=self.norm)\n",
    "    elif attack_type=='auto_projected_gradient_descent':\n",
    "        return AutoProjectedGradientDescent(estimator=self.classifier,\n",
    "                                          eps=self.epsilon,\n",
    "                                          eps_step=self.eps_iter,\n",
    "                                          norm=self.norm,\n",
    "                                          max_iter=self.iterations,\n",
    "                                          **kwargs)\n",
    "    elif attack_type=='carlini_wagner_l2':\n",
    "        return CarliniL2Method(self.classifier,\n",
    "                               max_iter=self.second_attack_iters,\n",
    "                               **kwargs)\n",
    "    elif attack_type=='newton_fool':\n",
    "        return NewtonFool(self.classifier,\n",
    "                        max_iter=self.iterations,\n",
    "                        **kwargs)\n",
    "    elif attack_type=='deep_fool':\n",
    "        return DeepFool(self.classifier,\n",
    "                      max_iter=self.iterations,\n",
    "                      epsilon=self.eps_iter,\n",
    "                      **kwargs)\n",
    "    elif attack_type=='elastic_net':\n",
    "        return ElasticNet(self.classifier,\n",
    "                      max_iter=self.second_attack_iters)\n",
    "    elif attack_type=='hop_skip_jump':\n",
    "        return HopSkipJump(self.classifier,\n",
    "                         norm=self.norm,\n",
    "                         max_iter=self.second_attack_iters)\n",
    "    else:\n",
    "        raise ValueError(f'Attack type \"{attack_type}\" not supported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plug-in Function for Adversarial Attack with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_with_early_stopping(classifier, x, y, max_iterations, attacker):\n",
    "    label_flipped = False\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    x = x.unsqueeze(0)\n",
    "\n",
    "    outputs = classifier.predict(x.cpu().numpy())\n",
    "    _, clean_predicted = torch.max(torch.tensor(outputs).to(device).data, 1)\n",
    "    \n",
    "    if int(clean_predicted.item()) != int(y.item()):\n",
    "        print('Misclassified input. Not attacking.')\n",
    "        end_time = time.time()\n",
    "        return x.cpu().detach().numpy(), end_time - start_time, 0\n",
    "\n",
    "    for j in range(max_iterations):\n",
    "        adv_inputs = attacker.generate(x.cpu().detach().numpy(), y.cpu().detach().numpy())\n",
    "\n",
    "        adv_inputs_tensor = torch.from_numpy(adv_inputs).to(device)\n",
    "        outputs = classifier.predict(adv_inputs)\n",
    "        _, predicted = torch.max(torch.tensor(outputs).to(device).data, 1)\n",
    "\n",
    "        label_flipped = bool(predicted.item() != int(y.item()))\n",
    "\n",
    "        if label_flipped:\n",
    "            print(f'\\tIterations for successful iterative attack: {j+1}')\n",
    "            break\n",
    "            \n",
    "        x = adv_inputs_tensor.clone()\n",
    "\n",
    "    end_time = time.time()\n",
    "    return adv_inputs, end_time - start_time, j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Adversarial Distance calculation (attack methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_calculation(classifier, xtest, ytest, epsilon, eps_iter, norm, max_iterations, attack_type, get_image: bool = False, verbose: bool = True):\n",
    "\n",
    "    distance_list, runtime_list = [], []\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    classifier.model.to(device)\n",
    "    xtest = xtest.to(device)\n",
    "    ytest = ytest.to(device)\n",
    "    \n",
    "    attacks = AdversarialAttacks(classifier=classifier,\n",
    "                          epsilon=epsilon,\n",
    "                          eps_iter=eps_iter,\n",
    "                          norm=norm,\n",
    "                          iterations=max_iterations,\n",
    "                          second_attack_iters=40)\n",
    "    attacker = attacks.init_attacker(attack_type)\n",
    "\n",
    "    correct_prediction = 0\n",
    "\n",
    "    for i, x in enumerate(xtest):\n",
    "        x = x.to(device)\n",
    "        y = ytest[i].unsqueeze(0).to(device)\n",
    "        \n",
    "        x_adversarial, runtime, iterations = attack_with_early_stopping(classifier=classifier,\n",
    "                                                            x=x,\n",
    "                                                            y=y,\n",
    "                                                            max_iterations=max_iterations,\n",
    "                                                            attacker=attacker)\n",
    "\n",
    "        x_adversarial_tensor = torch.from_numpy(x_adversarial).to(device)\n",
    "\n",
    "        # Adversarial accuracy calculation\n",
    "        output_adversarial = classifier.predict(x_adversarial)\n",
    "        _, predicted_adversarial = torch.max(torch.tensor(output_adversarial).to(device).data, 1)\n",
    "        correct_prediction += (predicted_adversarial.item() == int(y.item()))\n",
    "\n",
    "        distance = torch.norm((x - x_adversarial_tensor), p=float(norm))\n",
    "        if distance.item() == 0.0:\n",
    "            distance_list.append(0.0)\n",
    "            print(f'\\nMisclassified!!! dist: {distance.item()}\\n')\n",
    "        else:\n",
    "            distance_list.append(distance.item())\n",
    "        runtime_list.append(runtime)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Image {i}\\t\\tAdversarial_distance: {distance:.5f}\\t\\tRuntime: {runtime:5f} seconds')\n",
    "\n",
    "    if get_image:\n",
    "        get_example_image(x_adversarial, predicted_adversarial.item(), attack_type=attack_type)\n",
    "        get_example_image(x.unsqueeze(0).numpy(), y[i], attack_type='original')\n",
    "    \n",
    "    adversarial_accuracy = (correct_prediction / len(xtest)) * 100\n",
    "    print(f'\\nAdversarial accuracy: {adversarial_accuracy}%\\n')\n",
    "\n",
    "    return distance_list, runtime_list, adversarial_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = np.inf  # 1, 2, np.inf\n",
    "max_iterations = 500\n",
    "eps_iter_dict = {\n",
    "    'inf': 0.0003,\n",
    "    '1': 0.2,\n",
    "    '2': 0.005}\n",
    "eps_iter = eps_iter_dict[str(norm)]\n",
    "epsilon = max_iterations * eps_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitsize = 20       # full, int: splitsize\n",
    "xtest, ytest = load_dataset(dataset_split=splitsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy(net, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_types = [\n",
    "                'fast_gradient_method',\n",
    "                'projected_gradient_descent',\n",
    "                'auto_projected_gradient_descent',\n",
    "                'auto_conjugate_gradient',\n",
    "                'newton_fool',\n",
    "                'deep_fool',\n",
    "                'elastic_net',\n",
    "                'frame_saliency',\n",
    "                'auto_attack',\n",
    "                'carlini_wagner_linf',\n",
    "                'carlini_wagner_l2',\n",
    "                'hop_skip_jump'\n",
    "                ]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for attack_type in attack_types:\n",
    "    results_dict[attack_type] = {}\n",
    "    print(f'\\t\\t-------------------------- Processing Attack: {attack_type} --------------------------\\n')\n",
    "    results_dict[attack_type][\"adversarial_distance\"], results_dict[attack_type][\"runtime\"], results_dict[attack_type][\"adversarial_accuracy\"] = distance_calculation(classifier=classifier,\n",
    "                                                        xtest=xtest,\n",
    "                                                        ytest=ytest,\n",
    "                                                        epsilon=epsilon,\n",
    "                                                        eps_iter=eps_iter,\n",
    "                                                        norm=norm,\n",
    "                                                        max_iterations=max_iterations,\n",
    "                                                        attack_type=attack_type)\n",
    "    \n",
    "    mean_value = np.mean([x for x in results_dict[attack_type][\"adversarial_distance\"] if x is not None])\n",
    "\n",
    "    print(f'\\nMean adversarial distance for {attack_type}: {mean_value:.5f} with total runtime: {sum(results_dict[attack_type][\"runtime\"]): .5f} seconds\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results to JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = f'./data/attack_comparison_{modeltype}_L{norm}.json'\n",
    "\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(results_dict, f, indent=4)\n",
    "print(f'Evaluation results are saved under \"{json_file_path}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "for attack_type in attack_types:\n",
    "  plt.scatter(list(range(len(xtest))), results_dict[attack_type]['adversarial_distance'], label=attack_type)\n",
    "plt.xlabel('Image ID ----->')\n",
    "plt.ylabel('Distance ----->')\n",
    "plt.title(f'L{norm} Distance')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.xticks(list(range(len(xtest))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.plot(list(range(len(xtest))), results_dict[attack_type]['adversarial_distance'], label=attack_type)\n",
    "plt.xlabel('Image ID')\n",
    "plt.ylabel('Distance')\n",
    "plt.title(f'L{norm} Distance')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.xticks(list(range(len(xtest))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.plot(list(range(len(xtest))), results_dict[attack_type]['runtime'], label=attack_type)\n",
    "plt.xlabel('Image ID')\n",
    "plt.ylabel('Runtime [seconds]')\n",
    "plt.title('Step Runtime')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.bar(attack_type, results_dict[attack_type]['adversarial_accuracy'], label=attack_type)\n",
    "plt.xlabel('Attacks')\n",
    "plt.ylabel('Adversarial accuracy [%]')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.title('Adversarial Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.bar(attack_type, sum(results_dict[attack_type]['runtime']), label=attack_type)\n",
    "plt.xlabel('Attacks')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Runtime [seconds]')\n",
    "plt.title('Total Runtime')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
