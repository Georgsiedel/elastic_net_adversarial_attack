{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation and Repository cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp39-cp39-win_amd64.whl (2510.7 MB)\n",
      "     ---------------------------------------- 0.0/2.5 GB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.5 GB 29.3 MB/s eta 0:01:26\n",
      "     ---------------------------------------- 0.0/2.5 GB 28.8 MB/s eta 0:01:27\n",
      "     ---------------------------------------- 0.0/2.5 GB 29.1 MB/s eta 0:01:26\n",
      "     ---------------------------------------- 0.0/2.5 GB 28.9 MB/s eta 0:01:26\n",
      "     ---------------------------------------- 0.0/2.5 GB 28.8 MB/s eta 0:01:27\n",
      "      --------------------------------------- 0.0/2.5 GB 29.0 MB/s eta 0:01:26\n",
      "      --------------------------------------- 0.0/2.5 GB 28.9 MB/s eta 0:01:26\n",
      "      --------------------------------------- 0.0/2.5 GB 29.0 MB/s eta 0:01:26\n",
      "      --------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:25\n",
      "      --------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:25\n",
      "     - -------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:25\n",
      "     - -------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:25\n",
      "     - -------------------------------------- 0.1/2.5 GB 29.0 MB/s eta 0:01:25\n",
      "     - -------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 29.0 MB/s eta 0:01:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:24\n",
      "     - -------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:23\n",
      "     - -------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:23\n",
      "     -- ------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:23\n",
      "     -- ------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:23\n",
      "     -- ------------------------------------- 0.1/2.5 GB 28.8 MB/s eta 0:01:23\n",
      "     -- ------------------------------------- 0.1/2.5 GB 28.9 MB/s eta 0:01:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 28.9 MB/s eta 0:01:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 28.9 MB/s eta 0:01:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 28.9 MB/s eta 0:01:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 28.9 MB/s eta 0:01:22\n",
      "     -- ------------------------------------- 0.2/2.5 GB 28.9 MB/s eta 0:01:21\n",
      "     -- ------------------------------------- 0.2/2.5 GB 28.9 MB/s eta 0:01:21\n",
      "     -- ------------------------------------- 0.2/2.5 GB 28.9 MB/s eta 0:01:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 28.9 MB/s eta 0:01:21\n",
      "     --- ------------------------------------ 0.2/2.5 GB 28.9 MB/s eta 0:01:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 28.9 MB/s eta 0:01:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 28.9 MB/s eta 0:01:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 28.9 MB/s eta 0:01:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 28.9 MB/s eta 0:01:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 28.9 MB/s eta 0:01:20\n",
      "     --- ------------------------------------ 0.2/2.5 GB 28.9 MB/s eta 0:01:19\n",
      "     --- ------------------------------------ 0.2/2.5 GB 28.9 MB/s eta 0:01:19\n",
      "     --- ------------------------------------ 0.2/2.5 GB 28.9 MB/s eta 0:01:19\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 28.9 MB/s eta 0:01:19\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 28.9 MB/s eta 0:01:18\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 28.9 MB/s eta 0:01:18\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 28.9 MB/s eta 0:01:18\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 28.9 MB/s eta 0:01:18\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 28.9 MB/s eta 0:01:17\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 28.9 MB/s eta 0:01:17\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 28.7 MB/s eta 0:01:18\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 28.3 MB/s eta 0:01:19\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 28.3 MB/s eta 0:01:19\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 28.3 MB/s eta 0:01:18\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 28.3 MB/s eta 0:01:18\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 28.3 MB/s eta 0:01:18\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 28.3 MB/s eta 0:01:18\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 28.3 MB/s eta 0:01:18\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 28.3 MB/s eta 0:01:17\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 28.3 MB/s eta 0:01:17\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 28.3 MB/s eta 0:01:17\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:17\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:17\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:16\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:16\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:16\n",
      "     ------ --------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:16\n",
      "     ------ --------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:16\n",
      "     ------ --------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:15\n",
      "     ------ --------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:15\n",
      "     ------ --------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:15\n",
      "     ------ --------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:15\n",
      "     ------ --------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:14\n",
      "     ------ --------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:14\n",
      "     ------ --------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:14\n",
      "     ------ --------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:14\n",
      "     ------- -------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:14\n",
      "     ------- -------------------------------- 0.4/2.5 GB 28.3 MB/s eta 0:01:13\n",
      "     ------- -------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:13\n",
      "     ------- -------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:13\n",
      "     ------- -------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:13\n",
      "     ------- -------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:13\n",
      "     ------- -------------------------------- 0.5/2.5 GB 28.4 MB/s eta 0:01:12\n",
      "     ------- -------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:12\n",
      "     ------- -------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:12\n",
      "     ------- -------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:12\n",
      "     ------- -------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:12\n",
      "     -------- ------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:11\n",
      "     -------- ------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:11\n",
      "     -------- ------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:11\n",
      "     -------- ------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:11\n",
      "     -------- ------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:10\n",
      "     -------- ------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:10\n",
      "     -------- ------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:10\n",
      "     -------- ------------------------------- 0.5/2.5 GB 28.3 MB/s eta 0:01:10\n",
      "     -------- ------------------------------- 0.6/2.5 GB 28.9 MB/s eta 0:01:08\n",
      "     -------- ------------------------------- 0.6/2.5 GB 28.9 MB/s eta 0:01:08\n",
      "     -------- ------------------------------- 0.6/2.5 GB 28.9 MB/s eta 0:01:08\n",
      "     --------- ------------------------------ 0.6/2.5 GB 29.0 MB/s eta 0:01:07\n",
      "     --------- ------------------------------ 0.6/2.5 GB 28.9 MB/s eta 0:01:07\n",
      "     --------- ------------------------------ 0.6/2.5 GB 28.9 MB/s eta 0:01:07\n",
      "     --------- ------------------------------ 0.6/2.5 GB 28.3 MB/s eta 0:01:09\n",
      "     --------- ------------------------------ 0.6/2.5 GB 28.3 MB/s eta 0:01:08\n",
      "     --------- ------------------------------ 0.6/2.5 GB 28.3 MB/s eta 0:01:08\n",
      "     --------- ------------------------------ 0.6/2.5 GB 28.3 MB/s eta 0:01:08\n",
      "     --------- ------------------------------ 0.6/2.5 GB 28.3 MB/s eta 0:01:08\n",
      "     --------- ------------------------------ 0.6/2.5 GB 28.3 MB/s eta 0:01:08\n",
      "     --------- ------------------------------ 0.6/2.5 GB 28.3 MB/s eta 0:01:07\n",
      "     --------- ------------------------------ 0.6/2.5 GB 28.3 MB/s eta 0:01:07\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 28.3 MB/s eta 0:01:07\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 28.3 MB/s eta 0:01:07\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 28.3 MB/s eta 0:01:07\n",
      "     ---------- ----------------------------- 0.6/2.5 GB 28.3 MB/s eta 0:01:06\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:06\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:06\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:06\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:06\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:05\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:05\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:05\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:05\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:05\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:04\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:04\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:04\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:04\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 28.2 MB/s eta 0:01:04\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:03\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:03\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 28.3 MB/s eta 0:01:03\n",
      "     ----------- ---------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:03\n",
      "     ------------ --------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:03\n",
      "     ------------ --------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:02\n",
      "     ------------ --------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:02\n",
      "     ------------ --------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:02\n",
      "     ------------ --------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:02\n",
      "     ------------ --------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:01\n",
      "     ------------ --------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:01\n",
      "     ------------ --------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:01\n",
      "     ------------ --------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:01\n",
      "     ------------ --------------------------- 0.8/2.5 GB 28.2 MB/s eta 0:01:01\n",
      "     ------------- -------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:00\n",
      "     ------------- -------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:00\n",
      "     ------------- -------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:00\n",
      "     ------------- -------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:00\n",
      "     ------------- -------------------------- 0.8/2.5 GB 28.3 MB/s eta 0:01:00\n",
      "     ------------- -------------------------- 0.8/2.5 GB 28.9 MB/s eta 0:00:58\n",
      "     ------------- -------------------------- 0.9/2.5 GB 28.9 MB/s eta 0:00:58\n",
      "     ------------- -------------------------- 0.9/2.5 GB 28.9 MB/s eta 0:00:58\n",
      "     ------------- -------------------------- 0.9/2.5 GB 28.9 MB/s eta 0:00:57\n",
      "     ------------- -------------------------- 0.9/2.5 GB 28.9 MB/s eta 0:00:57\n",
      "     ------------- -------------------------- 0.9/2.5 GB 28.5 MB/s eta 0:00:58\n",
      "     ------------- -------------------------- 0.9/2.5 GB 28.3 MB/s eta 0:00:58\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.3 MB/s eta 0:00:58\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.3 MB/s eta 0:00:58\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.3 MB/s eta 0:00:58\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.3 MB/s eta 0:00:58\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.3 MB/s eta 0:00:57\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.3 MB/s eta 0:00:57\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.3 MB/s eta 0:00:57\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.3 MB/s eta 0:00:57\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.3 MB/s eta 0:00:56\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.3 MB/s eta 0:00:56\n",
      "     -------------- ------------------------- 0.9/2.5 GB 28.3 MB/s eta 0:00:56\n",
      "     --------------- ------------------------ 0.9/2.5 GB 28.3 MB/s eta 0:00:56\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.3 MB/s eta 0:00:56\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.3 MB/s eta 0:00:55\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.3 MB/s eta 0:00:55\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.3 MB/s eta 0:00:55\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.3 MB/s eta 0:00:55\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.3 MB/s eta 0:00:55\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.3 MB/s eta 0:00:54\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.3 MB/s eta 0:00:54\n",
      "     --------------- ------------------------ 1.0/2.5 GB 28.3 MB/s eta 0:00:54\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.3 MB/s eta 0:00:54\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.3 MB/s eta 0:00:54\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.3 MB/s eta 0:00:53\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.3 MB/s eta 0:00:53\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.3 MB/s eta 0:00:53\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.3 MB/s eta 0:00:53\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.3 MB/s eta 0:00:53\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 28.3 MB/s eta 0:00:52\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 28.3 MB/s eta 0:00:52\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 28.3 MB/s eta 0:00:52\n",
      "     ---------------- ----------------------- 1.1/2.5 GB 28.3 MB/s eta 0:00:52\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.3 MB/s eta 0:00:51\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.3 MB/s eta 0:00:51\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.3 MB/s eta 0:00:51\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.3 MB/s eta 0:00:51\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.3 MB/s eta 0:00:51\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.3 MB/s eta 0:00:50\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.3 MB/s eta 0:00:50\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.4 MB/s eta 0:00:50\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.3 MB/s eta 0:00:50\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.3 MB/s eta 0:00:50\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 28.2 MB/s eta 0:00:50\n",
      "     ------------------ --------------------- 1.1/2.5 GB 28.8 MB/s eta 0:00:48\n",
      "     ------------------ --------------------- 1.1/2.5 GB 28.7 MB/s eta 0:00:48\n",
      "     ------------------ --------------------- 1.1/2.5 GB 28.7 MB/s eta 0:00:48\n",
      "     ------------------ --------------------- 1.1/2.5 GB 28.6 MB/s eta 0:00:48\n",
      "     ------------------ --------------------- 1.2/2.5 GB 28.6 MB/s eta 0:00:48\n",
      "     ------------------ --------------------- 1.2/2.5 GB 28.5 MB/s eta 0:00:48\n",
      "     ------------------ --------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:49\n",
      "     ------------------ --------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:49\n",
      "     ------------------ --------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:49\n",
      "     ------------------ --------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:48\n",
      "     ------------------ --------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:48\n",
      "     ------------------ --------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:48\n",
      "     ------------------- -------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:48\n",
      "     ------------------- -------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:48\n",
      "     ------------------- -------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:47\n",
      "     ------------------- -------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:47\n",
      "     ------------------- -------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:47\n",
      "     ------------------- -------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:47\n",
      "     ------------------- -------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:47\n",
      "     ------------------- -------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:46\n",
      "     ------------------- -------------------- 1.2/2.5 GB 27.7 MB/s eta 0:00:46\n",
      "     ------------------- -------------------- 1.2/2.5 GB 27.8 MB/s eta 0:00:46\n",
      "     ------------------- -------------------- 1.3/2.5 GB 27.8 MB/s eta 0:00:46\n",
      "     -------------------- ------------------- 1.3/2.5 GB 27.8 MB/s eta 0:00:45\n",
      "     -------------------- ------------------- 1.3/2.5 GB 27.8 MB/s eta 0:00:45\n",
      "     -------------------- ------------------- 1.3/2.5 GB 27.8 MB/s eta 0:00:45\n",
      "     -------------------- ------------------- 1.3/2.5 GB 27.8 MB/s eta 0:00:45\n",
      "     -------------------- ------------------- 1.3/2.5 GB 27.8 MB/s eta 0:00:45\n",
      "     -------------------- ------------------- 1.3/2.5 GB 27.8 MB/s eta 0:00:44\n",
      "     -------------------- ------------------- 1.3/2.5 GB 27.8 MB/s eta 0:00:44\n",
      "     -------------------- ------------------- 1.3/2.5 GB 27.8 MB/s eta 0:00:44\n",
      "     -------------------- ------------------- 1.3/2.5 GB 27.8 MB/s eta 0:00:44\n",
      "     -------------------- ------------------- 1.3/2.5 GB 27.8 MB/s eta 0:00:44\n",
      "     -------------------- ------------------- 1.3/2.5 GB 27.8 MB/s eta 0:00:43\n",
      "     --------------------- ------------------ 1.3/2.5 GB 27.8 MB/s eta 0:00:43\n",
      "     --------------------- ------------------ 1.3/2.5 GB 27.8 MB/s eta 0:00:43\n",
      "     --------------------- ------------------ 1.3/2.5 GB 27.8 MB/s eta 0:00:43\n",
      "     --------------------- ------------------ 1.3/2.5 GB 27.8 MB/s eta 0:00:43\n",
      "     --------------------- ------------------ 1.3/2.5 GB 27.8 MB/s eta 0:00:42\n",
      "     --------------------- ------------------ 1.4/2.5 GB 27.8 MB/s eta 0:00:42\n",
      "     --------------------- ------------------ 1.4/2.5 GB 27.8 MB/s eta 0:00:42\n",
      "     --------------------- ------------------ 1.4/2.5 GB 27.8 MB/s eta 0:00:42\n",
      "     --------------------- ------------------ 1.4/2.5 GB 27.8 MB/s eta 0:00:42\n",
      "     --------------------- ------------------ 1.4/2.5 GB 27.8 MB/s eta 0:00:41\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 27.8 MB/s eta 0:00:41\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 27.9 MB/s eta 0:00:41\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 27.9 MB/s eta 0:00:40\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 28.0 MB/s eta 0:00:40\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 28.0 MB/s eta 0:00:40\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 28.2 MB/s eta 0:00:39\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 28.9 MB/s eta 0:00:38\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 28.9 MB/s eta 0:00:38\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 28.9 MB/s eta 0:00:38\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 28.9 MB/s eta 0:00:38\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 28.9 MB/s eta 0:00:37\n",
      "     ----------------------- ---------------- 1.4/2.5 GB 28.9 MB/s eta 0:00:37\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 28.9 MB/s eta 0:00:37\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 28.9 MB/s eta 0:00:37\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 29.0 MB/s eta 0:00:37\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 28.9 MB/s eta 0:00:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 28.9 MB/s eta 0:00:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 28.9 MB/s eta 0:00:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 28.9 MB/s eta 0:00:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 28.9 MB/s eta 0:00:36\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 28.8 MB/s eta 0:00:35\n",
      "     ------------------------ --------------- 1.5/2.5 GB 28.9 MB/s eta 0:00:35\n",
      "     ------------------------ --------------- 1.5/2.5 GB 28.8 MB/s eta 0:00:35\n",
      "     ------------------------ --------------- 1.5/2.5 GB 28.9 MB/s eta 0:00:35\n",
      "     ------------------------ --------------- 1.5/2.5 GB 28.8 MB/s eta 0:00:35\n",
      "     ------------------------ --------------- 1.5/2.5 GB 28.9 MB/s eta 0:00:34\n",
      "     ------------------------ --------------- 1.5/2.5 GB 28.9 MB/s eta 0:00:34\n",
      "     ------------------------ --------------- 1.5/2.5 GB 28.8 MB/s eta 0:00:34\n",
      "     ------------------------ --------------- 1.5/2.5 GB 28.8 MB/s eta 0:00:34\n",
      "     ------------------------ --------------- 1.6/2.5 GB 28.8 MB/s eta 0:00:34\n",
      "     ------------------------ --------------- 1.6/2.5 GB 28.8 MB/s eta 0:00:33\n",
      "     ------------------------ --------------- 1.6/2.5 GB 28.8 MB/s eta 0:00:33\n",
      "     ------------------------- -------------- 1.6/2.5 GB 28.8 MB/s eta 0:00:33\n",
      "     ------------------------- -------------- 1.6/2.5 GB 28.8 MB/s eta 0:00:33\n",
      "     ------------------------- -------------- 1.6/2.5 GB 28.8 MB/s eta 0:00:33\n",
      "     ------------------------- -------------- 1.6/2.5 GB 28.8 MB/s eta 0:00:33\n",
      "     ------------------------- -------------- 1.6/2.5 GB 28.3 MB/s eta 0:00:33\n",
      "     ------------------------- -------------- 1.6/2.5 GB 28.2 MB/s eta 0:00:33\n",
      "     ------------------------- -------------- 1.6/2.5 GB 28.2 MB/s eta 0:00:33\n",
      "     ------------------------- -------------- 1.6/2.5 GB 28.2 MB/s eta 0:00:33\n",
      "     ------------------------- -------------- 1.6/2.5 GB 28.2 MB/s eta 0:00:32\n",
      "     ------------------------- -------------- 1.6/2.5 GB 28.2 MB/s eta 0:00:32\n",
      "     ------------------------- -------------- 1.6/2.5 GB 28.2 MB/s eta 0:00:32\n",
      "     ------------------------- -------------- 1.6/2.5 GB 28.2 MB/s eta 0:00:32\n",
      "     -------------------------- ------------- 1.6/2.5 GB 28.2 MB/s eta 0:00:32\n",
      "     -------------------------- ------------- 1.6/2.5 GB 28.2 MB/s eta 0:00:31\n",
      "     -------------------------- ------------- 1.6/2.5 GB 28.2 MB/s eta 0:00:31\n",
      "     -------------------------- ------------- 1.7/2.5 GB 28.1 MB/s eta 0:00:31\n",
      "     -------------------------- ------------- 1.7/2.5 GB 28.1 MB/s eta 0:00:31\n",
      "     -------------------------- ------------- 1.7/2.5 GB 28.1 MB/s eta 0:00:31\n",
      "     -------------------------- ------------- 1.7/2.5 GB 28.1 MB/s eta 0:00:30\n",
      "     -------------------------- ------------- 1.7/2.5 GB 28.1 MB/s eta 0:00:30\n",
      "     -------------------------- ------------- 1.7/2.5 GB 28.1 MB/s eta 0:00:30\n",
      "     -------------------------- ------------- 1.7/2.5 GB 28.1 MB/s eta 0:00:30\n",
      "     -------------------------- ------------- 1.7/2.5 GB 28.0 MB/s eta 0:00:30\n",
      "     --------------------------- ------------ 1.7/2.5 GB 28.1 MB/s eta 0:00:29\n",
      "     --------------------------- ------------ 1.7/2.5 GB 28.1 MB/s eta 0:00:29\n",
      "     --------------------------- ------------ 1.7/2.5 GB 28.0 MB/s eta 0:00:29\n",
      "     --------------------------- ------------ 1.7/2.5 GB 28.1 MB/s eta 0:00:29\n",
      "     --------------------------- ------------ 1.7/2.5 GB 28.0 MB/s eta 0:00:29\n",
      "     --------------------------- ------------ 1.7/2.5 GB 28.0 MB/s eta 0:00:28\n",
      "     --------------------------- ------------ 1.7/2.5 GB 28.0 MB/s eta 0:00:28\n",
      "     --------------------------- ------------ 1.7/2.5 GB 28.0 MB/s eta 0:00:28\n",
      "     --------------------------- ------------ 1.7/2.5 GB 28.0 MB/s eta 0:00:28\n",
      "     --------------------------- ------------ 1.8/2.5 GB 28.1 MB/s eta 0:00:28\n",
      "     --------------------------- ------------ 1.8/2.5 GB 28.1 MB/s eta 0:00:27\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 28.1 MB/s eta 0:00:27\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 28.1 MB/s eta 0:00:27\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 28.1 MB/s eta 0:00:27\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 28.1 MB/s eta 0:00:26\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 28.1 MB/s eta 0:00:26\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 28.1 MB/s eta 0:00:26\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 28.1 MB/s eta 0:00:26\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 28.1 MB/s eta 0:00:26\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 28.2 MB/s eta 0:00:25\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 28.1 MB/s eta 0:00:25\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 28.2 MB/s eta 0:00:25\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 28.1 MB/s eta 0:00:25\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 28.1 MB/s eta 0:00:25\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 28.1 MB/s eta 0:00:24\n",
      "     ----------------------------- ---------- 1.8/2.5 GB 28.1 MB/s eta 0:00:24\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 28.8 MB/s eta 0:00:23\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 28.7 MB/s eta 0:00:23\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 28.8 MB/s eta 0:00:23\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 28.7 MB/s eta 0:00:23\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 28.7 MB/s eta 0:00:23\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 28.7 MB/s eta 0:00:23\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 28.2 MB/s eta 0:00:23\n",
      "     ------------------------------ --------- 1.9/2.5 GB 28.2 MB/s eta 0:00:23\n",
      "     ------------------------------ --------- 1.9/2.5 GB 28.2 MB/s eta 0:00:22\n",
      "     ------------------------------ --------- 1.9/2.5 GB 28.2 MB/s eta 0:00:22\n",
      "     ------------------------------ --------- 1.9/2.5 GB 28.2 MB/s eta 0:00:22\n",
      "     ------------------------------ --------- 1.9/2.5 GB 28.2 MB/s eta 0:00:22\n",
      "     ------------------------------ --------- 1.9/2.5 GB 28.2 MB/s eta 0:00:22\n",
      "     ------------------------------ --------- 1.9/2.5 GB 28.2 MB/s eta 0:00:21\n",
      "     ------------------------------ --------- 1.9/2.5 GB 28.2 MB/s eta 0:00:21\n",
      "     ------------------------------ --------- 1.9/2.5 GB 28.2 MB/s eta 0:00:21\n",
      "     ------------------------------ --------- 1.9/2.5 GB 28.3 MB/s eta 0:00:21\n",
      "     ------------------------------ --------- 1.9/2.5 GB 28.3 MB/s eta 0:00:21\n",
      "     ------------------------------- -------- 2.0/2.5 GB 28.3 MB/s eta 0:00:20\n",
      "     ------------------------------- -------- 2.0/2.5 GB 28.3 MB/s eta 0:00:20\n",
      "     ------------------------------- -------- 2.0/2.5 GB 28.3 MB/s eta 0:00:20\n",
      "     ------------------------------- -------- 2.0/2.5 GB 28.3 MB/s eta 0:00:20\n",
      "     ------------------------------- -------- 2.0/2.5 GB 28.3 MB/s eta 0:00:19\n",
      "     ------------------------------- -------- 2.0/2.5 GB 28.3 MB/s eta 0:00:19\n",
      "     ------------------------------- -------- 2.0/2.5 GB 28.3 MB/s eta 0:00:19\n",
      "     ------------------------------- -------- 2.0/2.5 GB 28.3 MB/s eta 0:00:19\n",
      "     ------------------------------- -------- 2.0/2.5 GB 28.3 MB/s eta 0:00:19\n",
      "     ------------------------------- -------- 2.0/2.5 GB 28.3 MB/s eta 0:00:18\n",
      "     -------------------------------- ------- 2.0/2.5 GB 28.3 MB/s eta 0:00:18\n",
      "     -------------------------------- ------- 2.0/2.5 GB 28.3 MB/s eta 0:00:18\n",
      "     -------------------------------- ------- 2.0/2.5 GB 28.3 MB/s eta 0:00:18\n",
      "     -------------------------------- ------- 2.0/2.5 GB 28.3 MB/s eta 0:00:18\n",
      "     -------------------------------- ------- 2.0/2.5 GB 28.3 MB/s eta 0:00:17\n",
      "     -------------------------------- ------- 2.0/2.5 GB 28.3 MB/s eta 0:00:17\n",
      "     -------------------------------- ------- 2.0/2.5 GB 28.3 MB/s eta 0:00:17\n",
      "     -------------------------------- ------- 2.1/2.5 GB 28.3 MB/s eta 0:00:17\n",
      "     -------------------------------- ------- 2.1/2.5 GB 28.3 MB/s eta 0:00:17\n",
      "     -------------------------------- ------- 2.1/2.5 GB 28.3 MB/s eta 0:00:16\n",
      "     -------------------------------- ------- 2.1/2.5 GB 28.3 MB/s eta 0:00:16\n",
      "     --------------------------------- ------ 2.1/2.5 GB 28.3 MB/s eta 0:00:16\n",
      "     --------------------------------- ------ 2.1/2.5 GB 28.3 MB/s eta 0:00:16\n",
      "     --------------------------------- ------ 2.1/2.5 GB 28.3 MB/s eta 0:00:15\n",
      "     --------------------------------- ------ 2.1/2.5 GB 28.3 MB/s eta 0:00:15\n",
      "     --------------------------------- ------ 2.1/2.5 GB 28.3 MB/s eta 0:00:15\n",
      "     --------------------------------- ------ 2.1/2.5 GB 28.3 MB/s eta 0:00:15\n",
      "     --------------------------------- ------ 2.1/2.5 GB 28.3 MB/s eta 0:00:15\n",
      "     --------------------------------- ------ 2.1/2.5 GB 28.3 MB/s eta 0:00:14\n",
      "     --------------------------------- ------ 2.1/2.5 GB 28.3 MB/s eta 0:00:14\n",
      "     --------------------------------- ------ 2.1/2.5 GB 28.3 MB/s eta 0:00:14\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 28.3 MB/s eta 0:00:14\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 28.9 MB/s eta 0:00:13\n",
      "     ---------------------------------- ----- 2.1/2.5 GB 28.9 MB/s eta 0:00:13\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 28.9 MB/s eta 0:00:13\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 28.9 MB/s eta 0:00:13\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 28.9 MB/s eta 0:00:12\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 28.8 MB/s eta 0:00:12\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 28.3 MB/s eta 0:00:13\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 28.3 MB/s eta 0:00:12\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 28.3 MB/s eta 0:00:12\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 28.3 MB/s eta 0:00:12\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 28.3 MB/s eta 0:00:12\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 28.3 MB/s eta 0:00:12\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 28.3 MB/s eta 0:00:11\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 28.3 MB/s eta 0:00:11\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 28.3 MB/s eta 0:00:11\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 28.3 MB/s eta 0:00:11\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 28.3 MB/s eta 0:00:10\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 28.3 MB/s eta 0:00:10\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 28.3 MB/s eta 0:00:10\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 28.3 MB/s eta 0:00:10\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 28.3 MB/s eta 0:00:10\n",
      "     ----------------------------------- ---- 2.3/2.5 GB 28.3 MB/s eta 0:00:09\n",
      "     ------------------------------------ --- 2.3/2.5 GB 28.3 MB/s eta 0:00:09\n",
      "     ------------------------------------ --- 2.3/2.5 GB 28.3 MB/s eta 0:00:09\n",
      "     ------------------------------------ --- 2.3/2.5 GB 28.3 MB/s eta 0:00:09\n",
      "     ------------------------------------ --- 2.3/2.5 GB 28.3 MB/s eta 0:00:09\n",
      "     ------------------------------------ --- 2.3/2.5 GB 28.3 MB/s eta 0:00:08\n",
      "     ------------------------------------ --- 2.3/2.5 GB 28.3 MB/s eta 0:00:08\n",
      "     ------------------------------------ --- 2.3/2.5 GB 28.3 MB/s eta 0:00:08\n",
      "     ------------------------------------ --- 2.3/2.5 GB 28.3 MB/s eta 0:00:08\n",
      "     ------------------------------------ --- 2.3/2.5 GB 28.3 MB/s eta 0:00:08\n",
      "     ------------------------------------ --- 2.3/2.5 GB 28.2 MB/s eta 0:00:07\n",
      "     ------------------------------------ --- 2.3/2.5 GB 28.3 MB/s eta 0:00:07\n",
      "     ------------------------------------- -- 2.3/2.5 GB 28.2 MB/s eta 0:00:07\n",
      "     ------------------------------------- -- 2.3/2.5 GB 28.3 MB/s eta 0:00:07\n",
      "     ------------------------------------- -- 2.3/2.5 GB 28.3 MB/s eta 0:00:07\n",
      "     ------------------------------------- -- 2.3/2.5 GB 28.3 MB/s eta 0:00:06\n",
      "     ------------------------------------- -- 2.4/2.5 GB 28.3 MB/s eta 0:00:06\n",
      "     ------------------------------------- -- 2.4/2.5 GB 28.2 MB/s eta 0:00:06\n",
      "     ------------------------------------- -- 2.4/2.5 GB 28.2 MB/s eta 0:00:06\n",
      "     ------------------------------------- -- 2.4/2.5 GB 28.2 MB/s eta 0:00:06\n",
      "     ------------------------------------- -- 2.4/2.5 GB 28.1 MB/s eta 0:00:05\n",
      "     ------------------------------------- -- 2.4/2.5 GB 28.2 MB/s eta 0:00:05\n",
      "     -------------------------------------- - 2.4/2.5 GB 28.2 MB/s eta 0:00:05\n",
      "     -------------------------------------- - 2.4/2.5 GB 28.2 MB/s eta 0:00:05\n",
      "     -------------------------------------- - 2.4/2.5 GB 28.1 MB/s eta 0:00:05\n",
      "     -------------------------------------- - 2.4/2.5 GB 28.2 MB/s eta 0:00:04\n",
      "     -------------------------------------- - 2.4/2.5 GB 28.2 MB/s eta 0:00:04\n",
      "     -------------------------------------- - 2.4/2.5 GB 28.2 MB/s eta 0:00:04\n",
      "     -------------------------------------- - 2.4/2.5 GB 28.2 MB/s eta 0:00:04\n",
      "     -------------------------------------- - 2.4/2.5 GB 28.2 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.4/2.5 GB 28.8 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.4/2.5 GB 28.8 MB/s eta 0:00:03\n",
      "     -------------------------------------- - 2.4/2.5 GB 28.8 MB/s eta 0:00:03\n",
      "     ---------------------------------------  2.5/2.5 GB 28.8 MB/s eta 0:00:03\n",
      "     ---------------------------------------  2.5/2.5 GB 28.7 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 28.6 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:02\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 28.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 28.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 28.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 GB 23.3 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp39-cp39-win_amd64.whl (6.1 MB)\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ---------------------------------------  6.0/6.1 MB 28.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.1/6.1 MB 25.1 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp39-cp39-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 4.1/4.1 MB 27.5 MB/s eta 0:00:00\n",
      "Collecting filelock (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/numpy-1.26.3-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/pillow-10.2.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Installing collected packages: mpmath, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.2.0 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 pillow-10.2.0 sympy-1.13.1 torch-2.5.1+cu124 torchaudio-2.5.1+cu124 torchvision-0.20.1+cu124\n",
      "Collecting adversarial-robustness-toolbox\n",
      "  Using cached adversarial_robustness_toolbox-1.18.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from adversarial-robustness-toolbox) (1.26.3)\n",
      "Collecting scipy>=1.4.1 (from adversarial-robustness-toolbox)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn>=0.22.2 (from adversarial-robustness-toolbox)\n",
      "  Using cached scikit_learn-1.5.2-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from adversarial-robustness-toolbox) (1.17.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from adversarial-robustness-toolbox) (57.4.0)\n",
      "Collecting tqdm (from adversarial-robustness-toolbox)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=0.22.2->adversarial-robustness-toolbox)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.22.2->adversarial-robustness-toolbox)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from tqdm->adversarial-robustness-toolbox) (0.4.6)\n",
      "Using cached adversarial_robustness_toolbox-1.18.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached scikit_learn-1.5.2-cp39-cp39-win_amd64.whl (11.0 MB)\n",
      "Using cached scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: tqdm, threadpoolctl, scipy, joblib, scikit-learn, adversarial-robustness-toolbox\n",
      "Successfully installed adversarial-robustness-toolbox-1.18.2 joblib-1.4.2 scikit-learn-1.5.2 scipy-1.13.1 threadpoolctl-3.5.0 tqdm-4.67.1\n",
      "Collecting git+https://github.com/RobustBench/robustbench.git\n",
      "  Cloning https://github.com/RobustBench/robustbench.git to c:\\users\\admin\\appdata\\local\\temp\\pip-req-build-yi2awuf6\n",
      "  Resolved https://github.com/RobustBench/robustbench.git to commit 776bc95bb4167827fb102a32ac5aea62e46cfaab\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting autoattack@ git+https://github.com/fra31/auto-attack.git@a39220048b3c9f2cca9a4d3a54604793c68eca7e#egg=autoattack (from robustbench==1.1)\n",
      "  Using cached autoattack-0.1-py3-none-any.whl\n",
      "Requirement already satisfied: torch>=1.7.1 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from robustbench==1.1) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from robustbench==1.1) (0.20.1+cu124)\n",
      "Collecting torchdiffeq (from robustbench==1.1)\n",
      "  Using cached torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
      "Collecting geotorch (from robustbench==1.1)\n",
      "  Using cached geotorch-0.3.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.25.0 (from robustbench==1.1)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: numpy>=1.19.4 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from robustbench==1.1) (1.26.3)\n",
      "Requirement already satisfied: Jinja2~=3.1.2 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from robustbench==1.1) (3.1.3)\n",
      "Requirement already satisfied: tqdm>=4.56.1 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from robustbench==1.1) (4.67.1)\n",
      "Collecting pandas>=1.3.5 (from robustbench==1.1)\n",
      "  Using cached pandas-2.2.3-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Collecting timm>=0.9.0 (from robustbench==1.1)\n",
      "  Using cached timm-1.0.12-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting gdown==5.1.0 (from robustbench==1.1)\n",
      "  Using cached gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting pyyaml (from robustbench==1.1)\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting beautifulsoup4 (from gdown==5.1.0->robustbench==1.1)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from gdown==5.1.0->robustbench==1.1) (3.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from Jinja2~=3.1.2->robustbench==1.1) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from pandas>=1.3.5->robustbench==1.1) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.3.5->robustbench==1.1)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.3.5->robustbench==1.1)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.25.0->robustbench==1.1)\n",
      "  Using cached charset_normalizer-3.4.0-cp39-cp39-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.25.0->robustbench==1.1)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.25.0->robustbench==1.1)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.25.0->robustbench==1.1)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting huggingface_hub (from timm>=0.9.0->robustbench==1.1)\n",
      "  Using cached huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm>=0.9.0->robustbench==1.1)\n",
      "  Using cached safetensors-0.4.5-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from torch>=1.7.1->robustbench==1.1) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from torch>=1.7.1->robustbench==1.1) (3.2.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from torch>=1.7.1->robustbench==1.1) (2024.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from torch>=1.7.1->robustbench==1.1) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.7.1->robustbench==1.1) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from torchvision>=0.8.2->robustbench==1.1) (10.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from tqdm>=4.56.1->robustbench==1.1) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.4.0 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from torchdiffeq->robustbench==1.1) (1.13.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->robustbench==1.1) (1.17.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown==5.1.0->robustbench==1.1)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from huggingface_hub->timm>=0.9.0->robustbench==1.1) (24.2)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown==5.1.0->robustbench==1.1)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Using cached pandas-2.2.3-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached timm-1.0.12-py3-none-any.whl (2.4 MB)\n",
      "Using cached geotorch-0.3.0-py3-none-any.whl (54 kB)\n",
      "Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Using cached torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp39-cp39-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Using cached safetensors-0.4.5-cp39-none-win_amd64.whl (286 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: robustbench\n",
      "  Building wheel for robustbench (pyproject.toml): started\n",
      "  Building wheel for robustbench (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for robustbench: filename=robustbench-1.1-py3-none-any.whl size=165221 sha256=654480658a4a6ba90bef9cb6f2b923c7b36c2adb202abbd0422e8d049b25ec68\n",
      "  Stored in directory: C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-fiyqo_0d\\wheels\\98\\2a\\0f\\a437e5748ae52c66bc5fa897e0b09118336526573ca2e74372\n",
      "Successfully built robustbench\n",
      "Installing collected packages: pytz, autoattack, urllib3, tzdata, soupsieve, safetensors, pyyaml, PySocks, idna, charset-normalizer, certifi, requests, pandas, beautifulsoup4, torchdiffeq, huggingface_hub, geotorch, timm, gdown, robustbench\n",
      "Successfully installed PySocks-1.7.1 autoattack-0.1 beautifulsoup4-4.12.3 certifi-2024.8.30 charset-normalizer-3.4.0 gdown-5.1.0 geotorch-0.3.0 huggingface_hub-0.26.5 idna-3.10 pandas-2.2.3 pytz-2024.2 pyyaml-6.0.2 requests-2.32.3 robustbench-1.1 safetensors-0.4.5 soupsieve-2.6 timm-1.0.12 torchdiffeq-0.2.5 tzdata-2024.2 urllib3-2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/RobustBench/robustbench.git 'C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-req-build-yi2awuf6'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.3-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.55.2-cp39-cp39-win_amd64.whl.metadata (168 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.9.3-cp39-cp39-win_amd64.whl (7.8 MB)\n",
      "Using cached contourpy-1.3.0-cp39-cp39-win_amd64.whl (211 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.55.2-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Using cached kiwisolver-1.4.7-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.55.2 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.9.3 pyparsing-3.2.0\n",
      "Requirement already satisfied: pillow in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (10.2.0)\n",
      "Collecting foolbox\n",
      "  Using cached foolbox-3.3.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from foolbox) (1.26.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from foolbox) (1.13.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from foolbox) (57.4.0)\n",
      "Collecting eagerpy>=0.30.0 (from foolbox)\n",
      "  Using cached eagerpy-0.30.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting GitPython>=3.0.7 (from foolbox)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from foolbox) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.24.0 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from foolbox) (2.32.3)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython>=3.0.7->foolbox)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from requests>=2.24.0->foolbox) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from requests>=2.24.0->foolbox) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from requests>=2.24.0->foolbox) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\desktop\\python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages (from requests>=2.24.0->foolbox) (2024.8.30)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=3.0.7->foolbox)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Using cached foolbox-3.3.4-py3-none-any.whl (1.7 MB)\n",
      "Using cached eagerpy-0.30.0-py3-none-any.whl (31 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, eagerpy, gitdb, GitPython, foolbox\n",
      "Successfully installed GitPython-3.1.43 eagerpy-0.30.0 foolbox-3.3.4 gitdb-4.0.11 smmap-5.0.1\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "#!pip install adversarial-robustness-toolbox -U\n",
    "#!pip install git+https://github.com/RobustBench/robustbench.git\n",
    "#!pip install matplotlib\n",
    "#!pip install pillow\n",
    "#!pip install foolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages\\timm\\models\\registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "c:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "c:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages\\timm\\models\\helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils\n",
    "import adversarial_attack.attack_utils as attack_utils\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Adversarial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages\\robustbench\\utils.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "model = 'Wang2023Better_WRN-28-10' # MainiAVG, MainiMSD, CroceL1, Wang2023Better_WRN-28-10, Wang2023Better_WRN-28-10\n",
    "net, art_net, fb_net, alias = utils.get_model(modelname=model, norm='L2') # specify the norm in case of robustbench models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "splitsize = 500 # full, int: splitsize\n",
    "xtest, ytest = utils.load_dataset(dataset_split=splitsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the test set is: 95.400%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.test_accuracy(net, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment = attack_utils.Experiment_class(art_net, fb_net, net, xtest, ytest, alias,\n",
    "                        epsilon = 12, \n",
    "                        eps_iter = 0.15,  \n",
    "                        norm = 1,  # 1, 2, np.inf\n",
    "                        max_iterations_fast_attacks = 10, \n",
    "                        max_iterations_slow_attacks = 10, \n",
    "                        verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Sweep Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.2, 0.5, 1.0, 2.0]\n",
      "\t\t-------------- Hyperparameter Sweep for Attack: exp_attack: learning_rate = 0.1 ----------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\adversarial_attack\\exp_attack.py:255: RuntimeWarning: invalid value encountered in log\n",
      "  v_val = np.where(abc>=15.0,np.log(abc)-np.log(np.log(abc))+np.log(np.log(abc))/np.log(abc), lambertw( np.exp(abc), k=0).real)/b-a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 images done. Current Adversarial Accuracy: 90.0%\n",
      "60 images done. Current Adversarial Accuracy: 86.66666666666667%\n",
      "80 images done. Current Adversarial Accuracy: 87.5%\n",
      "100 images done. Current Adversarial Accuracy: 88.0%\n",
      "120 images done. Current Adversarial Accuracy: 88.33333333333333%\n",
      "140 images done. Current Adversarial Accuracy: 87.14285714285714%\n",
      "160 images done. Current Adversarial Accuracy: 86.25%\n",
      "180 images done. Current Adversarial Accuracy: 85.55555555555556%\n",
      "200 images done. Current Adversarial Accuracy: 85.0%\n",
      "220 images done. Current Adversarial Accuracy: 84.54545454545455%\n",
      "240 images done. Current Adversarial Accuracy: 84.16666666666667%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m hyperparameter_range\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m0.2\u001b[39m,\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m1.0\u001b[39m,\u001b[38;5;241m2.0\u001b[39m]\n\u001b[0;32m      4\u001b[0m hyperparameter \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#'beta'\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m results_dict_hyperparameter_sweep \u001b[38;5;241m=\u001b[39m \u001b[43mExperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameter_sweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperparameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                               \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameter_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mattack_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattack_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\adversarial_attack\\attack_utils.py:56\u001b[0m, in \u001b[0;36mExperiment_class.hyperparameter_sweep\u001b[1;34m(self, hyperparameter, range, attack_type)\u001b[0m\n\u001b[0;32m     54\u001b[0m results_dict[hyperparameter\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(value)] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m-------------- Hyperparameter Sweep for Attack: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattack_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhyperparameter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ----------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m _, _, results_dict[hyperparameter\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(value)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madversarial_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m], _, results_dict[hyperparameter\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(value)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattack_success_rate_in_epsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m], results_dict[hyperparameter\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(value)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_adv_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m calculation(\n\u001b[0;32m     57\u001b[0m                                                     art_net\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mart_net,\n\u001b[0;32m     58\u001b[0m                                                     fb_net\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfb_net,\n\u001b[0;32m     59\u001b[0m                                                     net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet,\n\u001b[0;32m     60\u001b[0m                                                     xtest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxtest,\n\u001b[0;32m     61\u001b[0m                                                     ytest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mytest,\n\u001b[0;32m     62\u001b[0m                                                     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon,\n\u001b[0;32m     63\u001b[0m                                                     eps_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps_iter,\n\u001b[0;32m     64\u001b[0m                                                     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m     65\u001b[0m                                                     max_iterations_fast_attacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iterations_fast_attacks,\n\u001b[0;32m     66\u001b[0m                                                     max_iterations_slow_attacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iterations_slow_attacks,\n\u001b[0;32m     67\u001b[0m                                                     attack_type\u001b[38;5;241m=\u001b[39mattack_type,\n\u001b[0;32m     68\u001b[0m                                                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m     69\u001b[0m                                                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(hyperparameter\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(value), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m attack success rate in epsilon: \u001b[39m\u001b[38;5;124m'\u001b[39m, results_dict[hyperparameter\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(value)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattack_success_rate_in_epsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(hyperparameter\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(value), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m mean adv. distance: \u001b[39m\u001b[38;5;124m'\u001b[39m, results_dict[hyperparameter\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(value)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_adv_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\adversarial_attack\\attack_utils.py:189\u001b[0m, in \u001b[0;36mcalculation\u001b[1;34m(art_net, fb_net, net, xtest, ytest, epsilon, eps_iter, norm, max_iterations_slow_attacks, max_iterations_fast_attacks, attack_type, learning_rate, beta, verbose)\u001b[0m\n\u001b[0;32m    187\u001b[0m     x_adversarial \u001b[38;5;241m=\u001b[39m x_adversarial\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:             \n\u001b[1;32m--> 189\u001b[0m     x_adversarial \u001b[38;5;241m=\u001b[39m \u001b[43mattacker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m     x_adversarial \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x_adversarial)\n\u001b[0;32m    192\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\adversarial_attack\\exp_attack.py:129\u001b[0m, in \u001b[0;36mExpAttack.generate\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     x_batch \u001b[38;5;241m=\u001b[39m x_adv[batch_index_1:batch_index_2]\n\u001b[0;32m    128\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y[batch_index_1:batch_index_2]\n\u001b[1;32m--> 129\u001b[0m     x_adv[batch_index_1:batch_index_2] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Apply clip\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mclip_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\adversarial_attack\\exp_attack.py:177\u001b[0m, in \u001b[0;36mExpAttack._generate_batch\u001b[1;34m(self, x_batch, y_batch)\u001b[0m\n\u001b[0;32m    169\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinary search step \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m (c_mean==\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    171\u001b[0m     bss,\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary_search_steps,\n\u001b[0;32m    173\u001b[0m     np\u001b[38;5;241m.\u001b[39mmean(c_current),\n\u001b[0;32m    174\u001b[0m )\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# Run with 1 specific binary search step\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m best_dist, best_label, best_attack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_bss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_current\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Update best results so far\u001b[39;00m\n\u001b[0;32m    180\u001b[0m o_best_attack[best_dist \u001b[38;5;241m<\u001b[39m o_best_dist] \u001b[38;5;241m=\u001b[39m best_attack[best_dist \u001b[38;5;241m<\u001b[39m o_best_dist]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\adversarial_attack\\exp_attack.py:222\u001b[0m, in \u001b[0;36mExpAttack._generate_bss\u001b[1;34m(self, x_batch, y_batch, c_batch)\u001b[0m\n\u001b[0;32m    220\u001b[0m rnd\u001b[38;5;241m=\u001b[39mrnd\u001b[38;5;241m/\u001b[39m((np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(rnd)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39mrnd1\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# updating rule\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gradient_of_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_adv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_adv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmooth\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrnd\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_md(grad,delta,lower,upper)\n\u001b[0;32m    225\u001b[0m x_adv\u001b[38;5;241m=\u001b[39mx_0\u001b[38;5;241m+\u001b[39mdelta\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\adversarial_attack\\exp_attack.py:296\u001b[0m, in \u001b[0;36mExpAttack._gradient_of_loss\u001b[1;34m(self, target, x, x_adv, c_weight)\u001b[0m\n\u001b[0;32m    290\u001b[0m     i_sub \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\n\u001b[0;32m    291\u001b[0m         predictions \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m target) \u001b[38;5;241m+\u001b[39m (np\u001b[38;5;241m.\u001b[39mmin(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m*\u001b[39m target,\n\u001b[0;32m    292\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    293\u001b[0m     )\n\u001b[0;32m    294\u001b[0m cost\u001b[38;5;241m=\u001b[39mi_add\u001b[38;5;241m-\u001b[39mi_sub\n\u001b[1;32m--> 296\u001b[0m loss_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_adv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi_add\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m loss_gradient \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mclass_gradient(x_adv, label\u001b[38;5;241m=\u001b[39mi_sub)\n\u001b[0;32m    298\u001b[0m loss_gradient \u001b[38;5;241m=\u001b[39m loss_gradient\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages\\art\\estimators\\classification\\pytorch.py:683\u001b[0m, in \u001b[0;36mPyTorchClassifier.class_gradient\u001b[1;34m(self, x, label, training_mode, **kwargs)\u001b[0m\n\u001b[0;32m    681\u001b[0m unique_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(label))\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m unique_label:\n\u001b[1;32m--> 683\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_device\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    689\u001b[0m grads \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mswapaxes(np\u001b[38;5;241m.\u001b[39marray(grads_list), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    690\u001b[0m lst \u001b[38;5;241m=\u001b[39m [unique_label\u001b[38;5;241m.\u001b[39mindex(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m label]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Desktop\\Python\\elastic_net_adversarial_attack\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter sweep. Pick only one model.\n",
    "attack_type = 'exp_attack'\n",
    "hyperparameter_range=[0.1,0.2,0.5,1.0,2.0]\n",
    "hyperparameter = 'learning_rate' #'beta'\n",
    "\n",
    "results_dict_hyperparameter_sweep = Experiment.hyperparameter_sweep(hyperparameter=hyperparameter, \n",
    "                                               range=hyperparameter_range, \n",
    "                                               attack_type=attack_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elastic_net', 'exp_attack']\n",
      "\t\t-------------------------- Processing Attack: elastic_net --------------------------\n",
      "\n",
      "20 images done. Current Adversarial Accuracy: 55.0%\n",
      "60 images done. Current Adversarial Accuracy: 66.66666666666667%\n",
      "80 images done. Current Adversarial Accuracy: 67.5%\n",
      "100 images done. Current Adversarial Accuracy: 69.0%\n",
      "120 images done. Current Adversarial Accuracy: 68.33333333333333%\n",
      "140 images done. Current Adversarial Accuracy: 67.85714285714286%\n",
      "160 images done. Current Adversarial Accuracy: 67.5%\n",
      "180 images done. Current Adversarial Accuracy: 68.33333333333333%\n",
      "200 images done. Current Adversarial Accuracy: 67.5%\n",
      "240 images done. Current Adversarial Accuracy: 69.58333333333333%\n",
      "260 images done. Current Adversarial Accuracy: 70.38461538461539%\n",
      "280 images done. Current Adversarial Accuracy: 70.71428571428571%\n",
      "300 images done. Current Adversarial Accuracy: 71.33333333333333%\n",
      "340 images done. Current Adversarial Accuracy: 70.29411764705883%\n",
      "360 images done. Current Adversarial Accuracy: 68.88888888888889%\n",
      "380 images done. Current Adversarial Accuracy: 68.6842105263158%\n",
      "420 images done. Current Adversarial Accuracy: 69.04761904761905%\n",
      "440 images done. Current Adversarial Accuracy: 69.31818181818181%\n",
      "460 images done. Current Adversarial Accuracy: 69.34782608695652%\n",
      "480 images done. Current Adversarial Accuracy: 68.95833333333333%\n",
      "500 images done. Current Adversarial Accuracy: 69.0%\n",
      "\n",
      "Adversarial accuracy: 69.0%\n",
      "\n",
      "\n",
      "Total runtime:  780.14423 seconds\n",
      "\n",
      "attack success rate in epsilon:  16.666666666666664\n",
      "mean adv. distance:  40.05353979284061\n",
      "\t\t-------------------------- Processing Attack: exp_attack --------------------------\n",
      "\n",
      "20 images done. Current Adversarial Accuracy: 45.0%\n",
      "60 images done. Current Adversarial Accuracy: 63.333333333333336%\n",
      "80 images done. Current Adversarial Accuracy: 63.75%\n",
      "100 images done. Current Adversarial Accuracy: 66.0%\n",
      "120 images done. Current Adversarial Accuracy: 65.83333333333333%\n",
      "140 images done. Current Adversarial Accuracy: 65.71428571428571%\n",
      "160 images done. Current Adversarial Accuracy: 65.625%\n",
      "180 images done. Current Adversarial Accuracy: 66.11111111111111%\n",
      "200 images done. Current Adversarial Accuracy: 65.0%\n",
      "240 images done. Current Adversarial Accuracy: 65.41666666666667%\n",
      "260 images done. Current Adversarial Accuracy: 66.15384615384616%\n",
      "280 images done. Current Adversarial Accuracy: 66.42857142857143%\n",
      "300 images done. Current Adversarial Accuracy: 66.33333333333333%\n",
      "340 images done. Current Adversarial Accuracy: 65.88235294117646%\n",
      "360 images done. Current Adversarial Accuracy: 64.44444444444444%\n",
      "380 images done. Current Adversarial Accuracy: 64.47368421052632%\n",
      "420 images done. Current Adversarial Accuracy: 65.23809523809524%\n",
      "440 images done. Current Adversarial Accuracy: 65.45454545454545%\n",
      "460 images done. Current Adversarial Accuracy: 65.43478260869566%\n",
      "480 images done. Current Adversarial Accuracy: 65.20833333333333%\n",
      "500 images done. Current Adversarial Accuracy: 65.4%\n",
      "\n",
      "Adversarial accuracy: 65.4%\n",
      "\n",
      "\n",
      "Total runtime:  836.12783 seconds\n",
      "\n",
      "attack success rate in epsilon:  21.014492753623188\n",
      "mean adv. distance:  35.47753446635561\n",
      "Evaluation results are saved under \"./data/attack_comparison_MainiAVG.json\".\n"
     ]
    }
   ],
   "source": [
    "#Attack comparison\n",
    "attack_types = [#'fast_gradient_method', #bounded-full\n",
    "                #'projected_gradient_descent', #bounded-full\n",
    "                #'pgd_early_stopping', #not-bounded\n",
    "                #'auto_projected_gradient_descent', #bounded-full\n",
    "                #'deep_fool', #not-bounded\n",
    "                #'brendel_bethge', #bounded-min\n",
    "                #'carlini_wagner_l2', #not-bounded\n",
    "                'elastic_net', #not-bounded\n",
    "                'exp_attack',\n",
    "                #'exp_attack_smooth',\n",
    "                #'elastic_net_L1_rule', #not-bounded\n",
    "                #'elastic_net_L1_rule_higher_beta', #not-bounded\n",
    "                #'ART_AutoAttack', #bounded-full\n",
    "                #'original_AutoAttack', #bounded-full\n",
    "                ]\n",
    "\n",
    "results_dict_attack_comparison = Experiment.attack_comparison(attack_types)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
