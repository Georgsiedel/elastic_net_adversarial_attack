{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation and Repository cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install adversarial-robustness-toolbox -U\n",
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "#!pip install git+https://github.com/RobustBench/robustbench.git\n",
    "#!pip install matplotlib\n",
    "#!pip install pillow\n",
    "#!pip install foolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import json\n",
    "import foolbox as fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_split):\n",
    "    # Load CIFAR-10 dataset using torchvision\n",
    "    transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "                                 ])\n",
    "    testset = datasets.CIFAR10(root='./data/cifar', train=False, download=True, transform=transform)\n",
    "\n",
    "    # Truncated testset for experiments and ablations\n",
    "    if isinstance(dataset_split, int):\n",
    "        testset, _ = torch.utils.data.random_split(testset,\n",
    "                                                          [dataset_split, len(testset) - dataset_split],\n",
    "                                                          generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    # Extract data and labels from torchvision dataset\n",
    "    xtest = torch.stack([data[0] for data in testset])\n",
    "    ytest = torch.tensor([data[1] for data in testset])\n",
    "\n",
    "    return xtest, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Adversarial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robustbench.utils import load_model\n",
    "\n",
    "model_name = 'Sehwag2021Proxy_R18'\n",
    "net = load_model(model_name=model_name, dataset='cifar10', threat_model='L2')\n",
    "net = torch.nn.DataParallel(net)\n",
    "\n",
    "net.eval()\n",
    "net.to(device)\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# Initialize PyTorchClassifier for ART toolbox as a wrapper\n",
    "art_net = PyTorchClassifier(model=net,\n",
    "                               loss=criterion,\n",
    "                               optimizer=optimizer,\n",
    "                               input_shape=(3, 32, 32),\n",
    "                               nb_classes=10,\n",
    "                               device_type=device,\n",
    "                               clip_values=(0.0, 1.0))\n",
    "fb_net = fb.PyTorchModel(net, bounds=(0.0, 1.0), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Test Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, xtest, ytest):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(xtest)):\n",
    "            x = xtest[i].unsqueeze(0).to(device)\n",
    "            y = ytest[i].unsqueeze(0).to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += y.size(0)\n",
    "            correct += (predicted==y).sum().item()\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f'\\nAccuracy of the testset is: {accuracy:.3f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import (FastGradientMethod,\n",
    "                                 ProjectedGradientDescentPyTorch,\n",
    "                                 AutoProjectedGradientDescent,\n",
    "                                 AutoAttack,\n",
    "                                 CarliniL2Method,\n",
    "                                 DeepFool,\n",
    "                                 ElasticNet)\n",
    "from adversarial_attack.exp_attack import ExpAttack\n",
    "from adversarial_attack.acc_exp_attack import AccExpAttack\n",
    "from autoattack import AutoAttack as original_AutoAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialAttacks:\n",
    "  def __init__(self, art_net, net, epsilon, eps_iter, norm, max_iterations_fast_attacks, max_iterations_slow_attacks):\n",
    "    self.art_net = art_net\n",
    "    self.epsilon = epsilon\n",
    "    self.eps_iter = eps_iter\n",
    "    self.norm = norm\n",
    "    self.max_iterations_fast_attacks = max_iterations_fast_attacks\n",
    "    self.max_iterations_slow_attacks = max_iterations_slow_attacks\n",
    "    self.net = net\n",
    "  def init_attacker(self, attack_type, **kwargs):\n",
    "    if attack_type=='fast_gradient_method':\n",
    "        return FastGradientMethod(self.art_net,\n",
    "                                eps=self.epsilon,\n",
    "                                eps_step=self.epsilon,\n",
    "                                norm=self.norm,\n",
    "                                **kwargs)\n",
    "    elif attack_type=='projected_gradient_descent':\n",
    "        return ProjectedGradientDescentPyTorch(self.art_net,\n",
    "                                             eps=self.epsilon,\n",
    "                                             eps_step=self.eps_iter,\n",
    "                                             max_iter=self.max_iterations_fast_attacks,\n",
    "                                             norm=self.norm,\n",
    "                                             **kwargs)\n",
    "    elif attack_type=='pgd_early_stopping':\n",
    "        return ProjectedGradientDescentPyTorch(self.art_net,\n",
    "                                             eps=self.epsilon,\n",
    "                                             eps_step=self.eps_iter,\n",
    "                                             max_iter=1,\n",
    "                                             norm=self.norm,\n",
    "                                             **kwargs)\n",
    "    elif attack_type=='ART_AutoAttack':\n",
    "        return AutoAttack(estimator=self.art_net,\n",
    "                        eps=self.epsilon,\n",
    "                        eps_step=self.eps_iter,\n",
    "                        norm=self.norm)\n",
    "    elif attack_type=='original_AutoAttack':\n",
    "        return original_AutoAttack(net, \n",
    "                                   norm='L1', \n",
    "                                   eps=self.epsilon,\n",
    "                                   device=device)\n",
    "    elif attack_type=='auto_projected_gradient_descent':\n",
    "        return AutoProjectedGradientDescent(estimator=self.art_net,\n",
    "                                          eps=self.epsilon,\n",
    "                                          eps_step=self.eps_iter,\n",
    "                                          norm=self.norm,\n",
    "                                          max_iter=self.max_iterations_fast_attacks,\n",
    "                                          **kwargs)\n",
    "    elif attack_type=='brendel_bethge':\n",
    "        return fb.attacks.L1BrendelBethgeAttack(steps=self.max_iterations_fast_attacks)\n",
    "    elif attack_type=='carlini_wagner_l2':\n",
    "        return CarliniL2Method(self.art_net,\n",
    "                               max_iter=self.max_iterations_slow_attacks,\n",
    "                               **kwargs)\n",
    "    elif attack_type=='deep_fool':\n",
    "        return DeepFool(self.art_net,\n",
    "                      max_iter=self.max_iterations_fast_attacks,\n",
    "                      epsilon=self.eps_iter,\n",
    "                      **kwargs)\n",
    "    elif attack_type=='elastic_net':\n",
    "        return ElasticNet(self.art_net,\n",
    "                      max_iter=self.max_iterations_slow_attacks,learning_rate=0.01)\n",
    "    elif attack_type=='elastic_net_L1_rule':\n",
    "        return ElasticNet(self.art_net,\n",
    "                      max_iter=self.max_iterations_slow_attacks,\n",
    "                      decision_rule='L1')\n",
    "    elif attack_type=='elastic_net_L1_rule_higher_beta':\n",
    "        return ElasticNet(self.art_net,\n",
    "                      max_iter=self.max_iterations_slow_attacks,\n",
    "                      decision_rule='L1',\n",
    "                      beta=0.01,)\n",
    "    elif attack_type=='exp_attack':\n",
    "        return ExpAttack(self.art_net,\n",
    "                      max_iter=self.max_iterations_slow_attacks,learning_rate=1)\n",
    "    elif attack_type=='exp_attack_smooth':\n",
    "        return ExpAttack(self.art_net,\n",
    "                      max_iter=self.max_iterations_slow_attacks,learning_rate=1,smooth=True)\n",
    "    else:\n",
    "        raise ValueError(f'Attack type \"{attack_type}\" not supported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plug-in Function for Adversarial Attack with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_with_early_stopping(art_net, x, y, PGD_iterations, attacker):\n",
    "    label_flipped = False\n",
    "\n",
    "    for j in range(PGD_iterations):\n",
    "        adv_inputs = attacker.generate(x, y.numpy(), verbose=False)\n",
    "\n",
    "        outputs = art_net.predict(adv_inputs)\n",
    "        _, predicted = torch.max(torch.tensor(outputs).data, 1)\n",
    "        label_flipped = bool(predicted.item() != int(y.item()))\n",
    "\n",
    "        if label_flipped:\n",
    "            print(f'\\tIterations for successful iterative attack: {j+1}')\n",
    "            break\n",
    "        \n",
    "        x = adv_inputs.copy()\n",
    "            \n",
    "    return adv_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Adversarial Distance calculation (attack methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation(art_net, fb_net, net, xtest, ytest, epsilon, eps_iter, norm, max_iterations_slow_attacks, max_iterations_fast_attacks, attack_type, verbose: bool = False):\n",
    "\n",
    "    distance_list, runtime_list = [], []\n",
    "    art_net.model.to(device)\n",
    "    net.to(device)\n",
    "    \n",
    "    xtest = xtest.to(device)\n",
    "    ytest = ytest.to(device)\n",
    "    \n",
    "    attacks = AdversarialAttacks(art_net=art_net,\n",
    "                                 net = net,\n",
    "                          epsilon=epsilon,\n",
    "                          eps_iter=eps_iter,\n",
    "                          norm=norm,\n",
    "                          max_iterations_fast_attacks=max_iterations_fast_attacks,\n",
    "                          max_iterations_slow_attacks=max_iterations_slow_attacks)\n",
    "    attacker = attacks.init_attacker(attack_type)\n",
    "\n",
    "    robust_predictions = 0\n",
    "    attack_successes = 0\n",
    "    clean_correct = 0\n",
    "\n",
    "    for i, x in enumerate(xtest):\n",
    "\n",
    "        x = x.unsqueeze(0)\n",
    "        y = ytest[i].unsqueeze(0)\n",
    "        outputs = art_net.predict(x.cpu())\n",
    "        \n",
    "        _, clean_predicted = torch.max(torch.tensor(outputs).data, 1)\n",
    "            \n",
    "        if int(clean_predicted.item()) != int(y.item()):\n",
    "            print('Misclassified input. Not attacking.')\n",
    "            distance_list.append(False)\n",
    "            runtime_list.append(False)\n",
    "            continue        \n",
    "\n",
    "        clean_correct += 1\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        if attack_type == 'pgd_early_stopping':\n",
    "            x_adversarial = attack_with_early_stopping(art_net=art_net,\n",
    "                                                                x=x.numpy(),\n",
    "                                                                y=y,\n",
    "                                                                PGD_iterations=max_iterations_fast_attacks,\n",
    "                                                                attacker=attacker)\n",
    "            x_adversarial = torch.from_numpy(x_adversarial)\n",
    "        elif attack_type == 'brendel_bethge':\n",
    "            _, x_adversarial, _ = attacker(fb_net, x, y, epsilons=[epsilon])\n",
    "            x_adversarial = x_adversarial[0]\n",
    "        elif attack_type == 'original_AutoAttack':\n",
    "            x_adversarial = attacker.run_standard_evaluation(x, y)\n",
    "            x_adversarial = x_adversarial\n",
    "        else:             \n",
    "            x_adversarial = attacker.generate(x.cpu().numpy(), y.cpu().numpy())\n",
    "            x_adversarial = torch.from_numpy(x_adversarial)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        runtime = end_time - start_time\n",
    "        runtime_list.append(runtime)\n",
    "\n",
    "        # Adversarial accuracy calculation\n",
    "        output_adversarial = art_net.predict(x_adversarial)\n",
    "        _, predicted_adversarial = torch.max(torch.tensor(output_adversarial).data, 1)\n",
    "\n",
    "        # Adversarial distance calculation: if no AE found, save epsilon as distance, otherwise save the distance\n",
    "        if int(predicted_adversarial.item()) == int(y.item()):\n",
    "            robust_predictions += 1\n",
    "            distance = epsilon\n",
    "            distance_list.append(distance)\n",
    "            if verbose:\n",
    "                print(f'Image {i}: No adversarial example found.')\n",
    "        else:\n",
    "            distance = torch.norm((x.cpu() - x_adversarial), p=float(norm))\n",
    "            robust_predictions += (round(distance.item(), 2) > epsilon) \n",
    "            attack_successes += (round(distance.item(), 2) <= epsilon) \n",
    "            distance_list.append(min(distance.item(), epsilon)) #appending epsilon if distance of adversarial example is higher\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Image {i}\\t\\tAdversarial_distance: {distance:.5f}\\t\\tRuntime: {runtime:5f} seconds')\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f'{i+1} images done. Current Adversarial Accuracy: {robust_predictions/(i+1)}%')\n",
    "\n",
    "    adversarial_accuracy = (robust_predictions / len(xtest)) * 100\n",
    "    attack_success_rate = (attack_successes / clean_correct) * 100\n",
    "    print(f'\\nAdversarial accuracy: {adversarial_accuracy}%\\n')\n",
    "\n",
    "    return distance_list, runtime_list, adversarial_accuracy, attack_success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 1  # 1, 2, np.inf\n",
    "max_iterations_fast_attacks = 10\n",
    "max_iterations_slow_attacks = 10\n",
    "eps_iter = 0.15\n",
    "epsilon = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitsize = 50      # full, int: splitsize\n",
    "xtest, ytest = load_dataset(dataset_split=splitsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy(net, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_types = [#'fast_gradient_method', #bounded-full\n",
    "                #'projected_gradient_descent', #bounded-full\n",
    "                #'pgd_early_stopping', #not-bounded\n",
    "                #'auto_projected_gradient_descent', #bounded-full\n",
    "                #'deep_fool', #not-bounded\n",
    "                #'brendel_bethge', #bounded-min\n",
    "                #'carlini_wagner_l2', #not-bounded\n",
    "                'elastic_net', #not-bounded\n",
    "                'exp_attack',\n",
    "                'exp_attack_smooth',\n",
    "                #'elastic_net_L1_rule', #not-bounded\n",
    "                #'elastic_net_L1_rule_higher_beta', #not-bounded\n",
    "                #'ART_AutoAttack', #bounded-full\n",
    "                #'original_AutoAttack', #bounded-full\n",
    "                ]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for attack_type in attack_types:\n",
    "    results_dict[attack_type] = {}\n",
    "    print(f'\\t\\t-------------------------- Processing Attack: {attack_type} --------------------------\\n')\n",
    "    results_dict[attack_type][\"adversarial_distance\"], results_dict[attack_type][\"runtime\"], results_dict[attack_type][\"adversarial_accuracy\"] , results_dict[attack_type][\"attack_success_rate\"] = calculation(\n",
    "                                                        art_net=art_net,\n",
    "                                                        fb_net=fb_net,\n",
    "                                                        net = net,\n",
    "                                                        xtest=xtest,\n",
    "                                                        ytest=ytest,\n",
    "                                                        epsilon=epsilon,\n",
    "                                                        eps_iter=eps_iter,\n",
    "                                                        norm=norm,\n",
    "                                                        max_iterations_fast_attacks=max_iterations_fast_attacks,\n",
    "                                                        max_iterations_slow_attacks=max_iterations_slow_attacks,\n",
    "                                                        attack_type=attack_type,\n",
    "                                                        verbose=True)\n",
    "    \n",
    "    mean_value = np.mean([x for x in results_dict[attack_type][\"adversarial_distance\"] if x is not None])\n",
    "\n",
    "    print(f'\\nMean adversarial distance for {attack_type}: {mean_value:.5f} with total runtime: {sum(results_dict[attack_type][\"runtime\"]): .5f} seconds\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results to JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = f'./data/attack_comparison_{model_name}_L{norm}.json'\n",
    "\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(results_dict, f, indent=4)\n",
    "print(f'Evaluation results are saved under \"{json_file_path}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_types_with_distance = [\n",
    "                'brendel_bethge', #bounded-min\n",
    "                'pgd_early_stopping', #not-bounded\n",
    "                'deep_fool', #not-bounded\n",
    "                'carlini_wagner_l2', #not-bounded\n",
    "                'elastic_net', #not-bounded\n",
    "                'elastic_net_L1_rule', #not-bounded\n",
    "                'elastic_net_L1_rule_higher_beta', #not-bounded\n",
    "                'exp_attack', #not-bounded\n",
    "                'exp_attack_smooth', #not-bounded\n",
    "                ]\n",
    "\n",
    "selected_attack_types_with_distance = [a for a in attack_types if a in attack_types_with_distance]\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in selected_attack_types_with_distance:\n",
    "  plt.plot(list(range(len(xtest))), results_dict[attack_type]['adversarial_distance'], label=attack_type)\n",
    "plt.xlabel('Image ID')\n",
    "plt.ylabel('Distance')\n",
    "plt.title(f'L{norm} Distance')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.xticks(list(range(len(xtest))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.plot(list(range(len(xtest))), results_dict[attack_type]['runtime'], label=attack_type)\n",
    "plt.xlabel('Image ID')\n",
    "plt.ylabel('Runtime [seconds]')\n",
    "plt.title('Runtime per image')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.bar(attack_type, results_dict[attack_type]['adversarial_accuracy'], label=attack_type)\n",
    "plt.xlabel('Attacks')\n",
    "plt.ylabel('Adversarial accuracy [%]')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.title('Adversarial Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.bar(attack_type, results_dict[attack_type]['attack_success_rate'], label=attack_type)\n",
    "plt.xlabel('Attacks')\n",
    "plt.ylabel('Attack Success Rate [%]')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.title('Attack Success Rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.bar(attack_type, sum(results_dict[attack_type]['runtime'])/splitsize, label=attack_type)\n",
    "plt.xlabel('Attacks')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Runtime [seconds]')\n",
    "plt.title('Average Runtime per Image')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "art",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
