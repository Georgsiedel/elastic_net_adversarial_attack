{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation and Repository cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install adversarial-robustness-toolbox -U --quiet\n",
    "!pip install multiprocess --quiet\n",
    "!pip install importlib --quiet\n",
    "!pip install advertorch --quiet\n",
    "!git clone https://github.com/Georgsiedel/adversarial-distance-estimation.git\n",
    "!pip install git+https://github.com/RobustBench/robustbench.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import numba\n",
    "numba.__version__\n",
    "\n",
    "import importlib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageOps\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_split):\n",
    "    # Load CIFAR-10 dataset using torchvision\n",
    "    transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "                                 ])\n",
    "    testset = datasets.CIFAR10(root='./data/cifar', train=False, download=True, transform=transform)\n",
    "\n",
    "    # Truncated testset for experiments and ablations\n",
    "    if isinstance(dataset_split, int):\n",
    "        testset, _ = torch.utils.data.random_split(testset,\n",
    "                                                          [dataset_split, len(testset) - dataset_split],\n",
    "                                                          generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    # Extract data and labels from torchvision dataset\n",
    "    xtest = torch.stack([data[0] for data in testset])\n",
    "    ytest = torch.tensor([data[1] for data in testset])\n",
    "\n",
    "    return xtest, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare WideResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd /kaggle/working/adversarial-distance-estimation\n",
    "import models.wideresnet as wideresnet\n",
    "from robustbench.utils import load_model\n",
    "\n",
    "modeltype = 'adversarial'\n",
    "\n",
    "print(f'\\nLoading {modeltype} Model...\\n')\n",
    "if modeltype == 'standard':\n",
    "    net = wideresnet.WideResNet_28_4(10, 'CIFAR10', normalized=True, block=wideresnet.WideBasic, activation_function='relu')\n",
    "    state_dict = \"model_state_dict\"\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    PATH = f'./models/pretrained_models/{modeltype}.pth'\n",
    "    model = torch.load(PATH)\n",
    "    net.load_state_dict(model[state_dict], strict=False)\n",
    "elif modeltype == 'robust':\n",
    "    #self trained with massive random data augmentation and JSD consistency loss, but no adversarial objective\n",
    "    net = wideresnet.WideResNet_28_4(10, 'CIFAR10', normalized=True, block=wideresnet.WideBasic, activation_function='silu')\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    state_dict = \"model_state_dict\"\n",
    "    PATH = f'./models/pretrained_models/{modeltype}.pth'\n",
    "    model = torch.load(PATH)\n",
    "    net.load_state_dict(model[state_dict], strict=False)\n",
    "elif modeltype == 'adversarial':\n",
    "    #from https://github.com/BorealisAI/mma_training/tree/master/trained_models/cifar10-Linf-MMA-20-sd0\n",
    "    model_name = 'Ding2020MMA'\n",
    "    net = load_model(model_name=model_name, dataset='cifar10', threat_model='Linf')\n",
    "    net = torch.nn.DataParallel(net)\n",
    "\n",
    "%cd\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Test Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, xtest, ytest):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(xtest)):\n",
    "            x = xtest[i].unsqueeze(0).to(device)\n",
    "            y = ytest[i].unsqueeze(0).to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += y.size(0)\n",
    "            correct += (predicted==y).sum().item()\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f'\\nAccuracy of the testset is: {accuracy:.3f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# Initialize PyTorchClassifier for ART\n",
    "classifier = PyTorchClassifier(model=net,\n",
    "                               loss=criterion,\n",
    "                               optimizer=optimizer,\n",
    "                               input_shape=(3, 32, 32),\n",
    "                               nb_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import (FastGradientMethod,\n",
    "                                 ProjectedGradientDescentNumpy,\n",
    "                                 AutoAttack,\n",
    "                                 AutoProjectedGradientDescent,\n",
    "                                 CarliniL2Method,\n",
    "                                 NewtonFool,\n",
    "                                 DeepFool,\n",
    "                                 ElasticNet,\n",
    "                                 HopSkipJump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Attack Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialAttacks:\n",
    "  def __init__(self, classifier, epsilon, eps_iter, norm, iterations, second_attack_iters):\n",
    "    self.classifier = classifier\n",
    "    self.epsilon = epsilon\n",
    "    self.eps_iter = eps_iter\n",
    "    self.norm = norm\n",
    "    self.iterations = iterations\n",
    "    self.second_attack_iters = second_attack_iters\n",
    "\n",
    "  def init_attacker(self, attack_type, **kwargs):\n",
    "    if attack_type=='fast_gradient_method':\n",
    "        return FastGradientMethod(self.classifier,\n",
    "                                eps=self.epsilon,\n",
    "                                eps_step=self.eps_iter,\n",
    "                                minimal=True,\n",
    "                                norm=self.norm,\n",
    "                                **kwargs)\n",
    "    elif attack_type=='projected_gradient_descent':\n",
    "        return ProjectedGradientDescentNumpy(self.classifier,\n",
    "                                             eps=self.epsilon,\n",
    "                                             eps_step=self.eps_iter,\n",
    "                                             max_iter=self.iterations,\n",
    "                                             norm=self.norm,\n",
    "                                             **kwargs)\n",
    "    elif attack_type=='auto_attack':\n",
    "        return AutoAttack(estimator=self.classifier,\n",
    "                        eps=self.epsilon,\n",
    "                        eps_step=self.eps_iter,\n",
    "                        norm=self.norm)\n",
    "    elif attack_type=='auto_projected_gradient_descent':\n",
    "        return AutoProjectedGradientDescent(estimator=self.classifier,\n",
    "                                          eps=self.epsilon,\n",
    "                                          eps_step=self.eps_iter,\n",
    "                                          norm=self.norm,\n",
    "                                          max_iter=self.iterations,\n",
    "                                          **kwargs)\n",
    "    elif attack_type=='carlini_wagner_l2':\n",
    "        return CarliniL2Method(self.classifier,\n",
    "                               max_iter=self.second_attack_iters,\n",
    "                               **kwargs)\n",
    "    elif attack_type=='newton_fool':\n",
    "        return NewtonFool(self.classifier,\n",
    "                        max_iter=self.iterations,\n",
    "                        **kwargs)\n",
    "    elif attack_type=='deep_fool':\n",
    "        return DeepFool(self.classifier,\n",
    "                      max_iter=self.iterations,\n",
    "                      epsilon=self.eps_iter,\n",
    "                      **kwargs)\n",
    "    elif attack_type=='elastic_net':\n",
    "        return ElasticNet(self.classifier,\n",
    "                      max_iter=self.second_attack_iters)\n",
    "    elif attack_type=='hop_skip_jump':\n",
    "        return HopSkipJump(self.classifier,\n",
    "                         norm=self.norm,\n",
    "                         max_iter=self.second_attack_iters)\n",
    "    else:\n",
    "        raise ValueError(f'Attack type \"{attack_type}\" not supported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plug-in Function for Adversarial Attack with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_with_early_stopping(classifier, x, y, max_iterations, attacker):\n",
    "    label_flipped = False\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    x = x.unsqueeze(0)\n",
    "\n",
    "    outputs = classifier.predict(x.cpu().numpy())\n",
    "    _, clean_predicted = torch.max(torch.tensor(outputs).to(device).data, 1)\n",
    "    \n",
    "    if int(clean_predicted.item()) != int(y.item()):\n",
    "        print('Misclassified input. Not attacking.')\n",
    "        end_time = time.time()\n",
    "        return x.cpu().detach().numpy(), end_time - start_time, 0\n",
    "\n",
    "    for j in range(max_iterations):\n",
    "        adv_inputs = attacker.generate(x.cpu().detach().numpy(), y.cpu().detach().numpy())\n",
    "\n",
    "        adv_inputs_tensor = torch.from_numpy(adv_inputs).to(device)\n",
    "        outputs = classifier.predict(adv_inputs)\n",
    "        _, predicted = torch.max(torch.tensor(outputs).to(device).data, 1)\n",
    "\n",
    "        label_flipped = bool(predicted.item() != int(y.item()))\n",
    "\n",
    "        if label_flipped:\n",
    "            print(f'\\tIterations for successful iterative attack: {j+1}')\n",
    "            break\n",
    "            \n",
    "        x = adv_inputs_tensor.clone()\n",
    "\n",
    "    end_time = time.time()\n",
    "    return adv_inputs, end_time - start_time, j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Adversarial Distance calculation (attack methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_calculation(classifier, xtest, ytest, epsilon, eps_iter, norm, max_iterations, attack_type, get_image: bool = False, verbose: bool = True):\n",
    "\n",
    "    distance_list, runtime_list = [], []\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    classifier.model.to(device)\n",
    "    xtest = xtest.to(device)\n",
    "    ytest = ytest.to(device)\n",
    "    \n",
    "    attacks = AdversarialAttacks(classifier=classifier,\n",
    "                          epsilon=epsilon,\n",
    "                          eps_iter=eps_iter,\n",
    "                          norm=norm,\n",
    "                          iterations=max_iterations,\n",
    "                          second_attack_iters=40)\n",
    "    attacker = attacks.init_attacker(attack_type)\n",
    "\n",
    "    correct_prediction = 0\n",
    "\n",
    "    for i, x in enumerate(xtest):\n",
    "        x = x.to(device)\n",
    "        y = ytest[i].unsqueeze(0).to(device)\n",
    "        \n",
    "        x_adversarial, runtime, iterations = attack_with_early_stopping(classifier=classifier,\n",
    "                                                            x=x,\n",
    "                                                            y=y,\n",
    "                                                            max_iterations=max_iterations,\n",
    "                                                            attacker=attacker)\n",
    "\n",
    "        x_adversarial_tensor = torch.from_numpy(x_adversarial).to(device)\n",
    "\n",
    "        # Adversarial accuracy calculation\n",
    "        output_adversarial = classifier.predict(x_adversarial)\n",
    "        _, predicted_adversarial = torch.max(torch.tensor(output_adversarial).to(device).data, 1)\n",
    "        correct_prediction += (predicted_adversarial.item() == int(y.item()))\n",
    "\n",
    "        distance = torch.norm((x - x_adversarial_tensor), p=float(norm))\n",
    "        if distance.item() == 0.0:\n",
    "            distance_list.append(0.0)\n",
    "            print(f'\\nMisclassified!!! dist: {distance.item()}\\n')\n",
    "        else:\n",
    "            distance_list.append(distance.item())\n",
    "        runtime_list.append(runtime)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Image {i}\\t\\tAdversarial_distance: {distance:.5f}\\t\\tRuntime: {runtime:5f} seconds')\n",
    "\n",
    "    if get_image:\n",
    "        get_example_image(x_adversarial, predicted_adversarial.item(), attack_type=attack_type)\n",
    "        get_example_image(x.unsqueeze(0).numpy(), y[i], attack_type='original')\n",
    "    \n",
    "    adversarial_accuracy = (correct_prediction / len(xtest)) * 100\n",
    "    print(f'\\nAdversarial accuracy: {adversarial_accuracy}%\\n')\n",
    "\n",
    "    return distance_list, runtime_list, adversarial_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = np.inf  # 1, 2, np.inf\n",
    "max_iterations = 500\n",
    "eps_iter_dict = {\n",
    "    'inf': 0.0003,\n",
    "    '1': 0.2,\n",
    "    '2': 0.005}\n",
    "eps_iter = eps_iter_dict[str(norm)]\n",
    "epsilon = max_iterations * eps_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitsize = 20       # full, int: splitsize\n",
    "xtest, ytest = load_dataset(dataset_split=splitsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy(net, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_types = [\n",
    "                'fast_gradient_method',\n",
    "                'projected_gradient_descent',\n",
    "                'auto_projected_gradient_descent',\n",
    "                'auto_conjugate_gradient',\n",
    "                'newton_fool',\n",
    "                'deep_fool',\n",
    "                'elastic_net',\n",
    "                'frame_saliency',\n",
    "                'auto_attack',\n",
    "                'carlini_wagner_linf',\n",
    "                'carlini_wagner_l2',\n",
    "                'hop_skip_jump'\n",
    "                ]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for attack_type in attack_types:\n",
    "    results_dict[attack_type] = {}\n",
    "    print(f'\\t\\t-------------------------- Processing Attack: {attack_type} --------------------------\\n')\n",
    "    results_dict[attack_type][\"adversarial_distance\"], results_dict[attack_type][\"runtime\"], results_dict[attack_type][\"adversarial_accuracy\"] = distance_calculation(classifier=classifier,\n",
    "                                                        xtest=xtest,\n",
    "                                                        ytest=ytest,\n",
    "                                                        epsilon=epsilon,\n",
    "                                                        eps_iter=eps_iter,\n",
    "                                                        norm=norm,\n",
    "                                                        max_iterations=max_iterations,\n",
    "                                                        attack_type=attack_type)\n",
    "    \n",
    "    mean_value = np.mean([x for x in results_dict[attack_type][\"adversarial_distance\"] if x is not None])\n",
    "\n",
    "    print(f'\\nMean adversarial distance for {attack_type}: {mean_value:.5f} with total runtime: {sum(results_dict[attack_type][\"runtime\"]): .5f} seconds\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results to JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = f'./data/attack_comparison_{modeltype}_L{norm}.json'\n",
    "\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(results_dict, f, indent=4)\n",
    "print(f'Evaluation results are saved under \"{json_file_path}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "for attack_type in attack_types:\n",
    "  plt.scatter(list(range(len(xtest))), results_dict[attack_type]['adversarial_distance'], label=attack_type)\n",
    "plt.xlabel('Image ID ----->')\n",
    "plt.ylabel('Distance ----->')\n",
    "plt.title(f'L{norm} Distance')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.xticks(list(range(len(xtest))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.plot(list(range(len(xtest))), results_dict[attack_type]['adversarial_distance'], label=attack_type)\n",
    "plt.xlabel('Image ID')\n",
    "plt.ylabel('Distance')\n",
    "plt.title(f'L{norm} Distance')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.xticks(list(range(len(xtest))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.plot(list(range(len(xtest))), results_dict[attack_type]['runtime'], label=attack_type)\n",
    "plt.xlabel('Image ID')\n",
    "plt.ylabel('Runtime [seconds]')\n",
    "plt.title('Step Runtime')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.bar(attack_type, results_dict[attack_type]['adversarial_accuracy'], label=attack_type)\n",
    "plt.xlabel('Attacks')\n",
    "plt.ylabel('Adversarial accuracy [%]')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.title('Adversarial Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.bar(attack_type, sum(results_dict[attack_type]['runtime']), label=attack_type)\n",
    "plt.xlabel('Attacks')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Runtime [seconds]')\n",
    "plt.title('Total Runtime')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
