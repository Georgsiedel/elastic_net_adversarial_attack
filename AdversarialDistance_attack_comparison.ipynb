{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation and Repository cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install adversarial-robustness-toolbox -U\n",
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "#!pip install git+https://github.com/RobustBench/robustbench.git\n",
    "#!pip install matplotlib\n",
    "#!pip install pillow\n",
    "#!pip install foolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import json\n",
    "import foolbox as fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_split):\n",
    "    # Load CIFAR-10 dataset using torchvision\n",
    "    transform = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "                                 ])\n",
    "    testset = datasets.CIFAR10(root='./data/cifar', train=False, download=True, transform=transform)\n",
    "\n",
    "    # Truncated testset for experiments and ablations\n",
    "    if isinstance(dataset_split, int):\n",
    "        testset, _ = torch.utils.data.random_split(testset,\n",
    "                                                          [dataset_split, len(testset) - dataset_split],\n",
    "                                                          generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    # Extract data and labels from torchvision dataset\n",
    "    xtest = torch.stack([data[0] for data in testset])\n",
    "    ytest = torch.tensor([data[1] for data in testset])\n",
    "\n",
    "    return xtest, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Adversarial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shao/anaconda3/envs/art/lib/python3.12/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/home/shao/anaconda3/envs/art/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/home/shao/anaconda3/envs/art/lib/python3.12/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/home/shao/anaconda3/envs/art/lib/python3.12/site-packages/robustbench/utils.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "from robustbench.utils import load_model\n",
    "\n",
    "model_name = 'Sehwag2021Proxy_R18'\n",
    "net = load_model(model_name=model_name, dataset='cifar10', threat_model='L2')\n",
    "net = torch.nn.DataParallel(net)\n",
    "\n",
    "net.eval()\n",
    "net.to(device)\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# Initialize PyTorchClassifier for ART toolbox as a wrapper\n",
    "art_net = PyTorchClassifier(model=net,\n",
    "                               loss=criterion,\n",
    "                               optimizer=optimizer,\n",
    "                               input_shape=(3, 32, 32),\n",
    "                               nb_classes=10,\n",
    "                               device_type=device,\n",
    "                               clip_values=(0.0, 1.0))\n",
    "fb_net = fb.PyTorchModel(net, bounds=(0.0, 1.0), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Test Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, xtest, ytest):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(xtest)):\n",
    "            x = xtest[i].unsqueeze(0).to(device)\n",
    "            y = ytest[i].unsqueeze(0).to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += y.size(0)\n",
    "            correct += (predicted==y).sum().item()\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f'\\nAccuracy of the testset is: {accuracy:.3f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import (FastGradientMethod,\n",
    "                                 ProjectedGradientDescentPyTorch,\n",
    "                                 AutoProjectedGradientDescent,\n",
    "                                 AutoAttack,\n",
    "                                 CarliniL2Method,\n",
    "                                 DeepFool,\n",
    "                                 ElasticNet)\n",
    "from adversarial_attack.exp_attack import ExpAttack\n",
    "from adversarial_attack.acc_exp_attack import AccExpAttack\n",
    "from autoattack import AutoAttack as original_AutoAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialAttacks:\n",
    "  def __init__(self, art_net, net, epsilon, eps_iter, norm, max_iterations_fast_attacks, max_iterations_slow_attacks):\n",
    "    self.art_net = art_net\n",
    "    self.epsilon = epsilon\n",
    "    self.eps_iter = eps_iter\n",
    "    self.norm = norm\n",
    "    self.max_iterations_fast_attacks = max_iterations_fast_attacks\n",
    "    self.max_iterations_slow_attacks = max_iterations_slow_attacks\n",
    "    self.net = net\n",
    "  def init_attacker(self, attack_type, **kwargs):\n",
    "    if attack_type=='fast_gradient_method':\n",
    "        return FastGradientMethod(self.art_net,\n",
    "                                eps=self.epsilon,\n",
    "                                eps_step=self.epsilon,\n",
    "                                norm=self.norm,\n",
    "                                **kwargs)\n",
    "    elif attack_type=='projected_gradient_descent':\n",
    "        return ProjectedGradientDescentPyTorch(self.art_net,\n",
    "                                             eps=self.epsilon,\n",
    "                                             eps_step=self.eps_iter,\n",
    "                                             max_iter=self.max_iterations_fast_attacks,\n",
    "                                             norm=self.norm,\n",
    "                                             **kwargs)\n",
    "    elif attack_type=='pgd_early_stopping':\n",
    "        return ProjectedGradientDescentPyTorch(self.art_net,\n",
    "                                             eps=self.epsilon,\n",
    "                                             eps_step=self.eps_iter,\n",
    "                                             max_iter=1,\n",
    "                                             norm=self.norm,\n",
    "                                             **kwargs)\n",
    "    elif attack_type=='ART_AutoAttack':\n",
    "        return AutoAttack(estimator=self.art_net,\n",
    "                        eps=self.epsilon,\n",
    "                        eps_step=self.eps_iter,\n",
    "                        norm=self.norm)\n",
    "    elif attack_type=='original_AutoAttack':\n",
    "        return original_AutoAttack(net, \n",
    "                                   norm='L1', \n",
    "                                   eps=self.epsilon,\n",
    "                                   device=device)\n",
    "    elif attack_type=='auto_projected_gradient_descent':\n",
    "        return AutoProjectedGradientDescent(estimator=self.art_net,\n",
    "                                          eps=self.epsilon,\n",
    "                                          eps_step=self.eps_iter,\n",
    "                                          norm=self.norm,\n",
    "                                          max_iter=self.max_iterations_fast_attacks,\n",
    "                                          **kwargs)\n",
    "    elif attack_type=='brendel_bethge':\n",
    "        return fb.attacks.L1BrendelBethgeAttack(steps=self.max_iterations_fast_attacks)\n",
    "    elif attack_type=='carlini_wagner_l2':\n",
    "        return CarliniL2Method(self.art_net,\n",
    "                               max_iter=self.max_iterations_slow_attacks,\n",
    "                               **kwargs)\n",
    "    elif attack_type=='deep_fool':\n",
    "        return DeepFool(self.art_net,\n",
    "                      max_iter=self.max_iterations_fast_attacks,\n",
    "                      epsilon=self.eps_iter,\n",
    "                      **kwargs)\n",
    "    elif attack_type=='elastic_net':\n",
    "        return ElasticNet(self.art_net,\n",
    "                      max_iter=self.max_iterations_slow_attacks,learning_rate=0.01)\n",
    "    elif attack_type=='elastic_net_L1_rule':\n",
    "        return ElasticNet(self.art_net,\n",
    "                      max_iter=self.max_iterations_slow_attacks,\n",
    "                      decision_rule='L1')\n",
    "    elif attack_type=='elastic_net_L1_rule_higher_beta':\n",
    "        return ElasticNet(self.art_net,\n",
    "                      max_iter=self.max_iterations_slow_attacks,\n",
    "                      decision_rule='L1',\n",
    "                      beta=0.01,)\n",
    "    elif attack_type=='exp_attack':\n",
    "        return ExpAttack(self.art_net,\n",
    "                      max_iter=self.max_iterations_slow_attacks,learning_rate=1)\n",
    "    elif attack_type=='acc_exp_attack':\n",
    "        return AccExpAttack(self.art_net,\n",
    "                      max_iter=self.max_iterations_slow_attacks,learning_rate=1)\n",
    "    else:\n",
    "        raise ValueError(f'Attack type \"{attack_type}\" not supported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plug-in Function for Adversarial Attack with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_with_early_stopping(art_net, x, y, PGD_iterations, attacker):\n",
    "    label_flipped = False\n",
    "\n",
    "    for j in range(PGD_iterations):\n",
    "        adv_inputs = attacker.generate(x, y.numpy(), verbose=False)\n",
    "\n",
    "        outputs = art_net.predict(adv_inputs)\n",
    "        _, predicted = torch.max(torch.tensor(outputs).data, 1)\n",
    "        label_flipped = bool(predicted.item() != int(y.item()))\n",
    "\n",
    "        if label_flipped:\n",
    "            print(f'\\tIterations for successful iterative attack: {j+1}')\n",
    "            break\n",
    "        \n",
    "        x = adv_inputs.copy()\n",
    "            \n",
    "    return adv_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Adversarial Distance calculation (attack methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation(art_net, fb_net, net, xtest, ytest, epsilon, eps_iter, norm, max_iterations_slow_attacks, max_iterations_fast_attacks, attack_type, verbose: bool = False):\n",
    "\n",
    "    distance_list, runtime_list = [], []\n",
    "    art_net.model.to(device)\n",
    "    net.to(device)\n",
    "    \n",
    "    xtest = xtest.to(device)\n",
    "    ytest = ytest.to(device)\n",
    "    \n",
    "    attacks = AdversarialAttacks(art_net=art_net,\n",
    "                                 net = net,\n",
    "                          epsilon=epsilon,\n",
    "                          eps_iter=eps_iter,\n",
    "                          norm=norm,\n",
    "                          max_iterations_fast_attacks=max_iterations_fast_attacks,\n",
    "                          max_iterations_slow_attacks=max_iterations_slow_attacks)\n",
    "    attacker = attacks.init_attacker(attack_type)\n",
    "\n",
    "    robust_predictions = 0\n",
    "    attack_successes = 0\n",
    "    clean_correct = 0\n",
    "\n",
    "    for i, x in enumerate(xtest):\n",
    "\n",
    "        x = x.unsqueeze(0)\n",
    "        y = ytest[i].unsqueeze(0)\n",
    "        outputs = art_net.predict(x.cpu())\n",
    "        \n",
    "        _, clean_predicted = torch.max(torch.tensor(outputs).data, 1)\n",
    "            \n",
    "        if int(clean_predicted.item()) != int(y.item()):\n",
    "            print('Misclassified input. Not attacking.')\n",
    "            distance_list.append(False)\n",
    "            runtime_list.append(False)\n",
    "            continue        \n",
    "\n",
    "        clean_correct += 1\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        if attack_type == 'pgd_early_stopping':\n",
    "            x_adversarial = attack_with_early_stopping(art_net=art_net,\n",
    "                                                                x=x.numpy(),\n",
    "                                                                y=y,\n",
    "                                                                PGD_iterations=max_iterations_fast_attacks,\n",
    "                                                                attacker=attacker)\n",
    "            x_adversarial = torch.from_numpy(x_adversarial)\n",
    "        elif attack_type == 'brendel_bethge':\n",
    "            _, x_adversarial, _ = attacker(fb_net, x, y, epsilons=[epsilon])\n",
    "            x_adversarial = x_adversarial[0]\n",
    "        elif attack_type == 'original_AutoAttack':\n",
    "            x_adversarial = attacker.run_standard_evaluation(x, y)\n",
    "            x_adversarial = x_adversarial\n",
    "        else:             \n",
    "            x_adversarial = attacker.generate(x.cpu().numpy(), y.cpu().numpy())\n",
    "            x_adversarial = torch.from_numpy(x_adversarial)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        runtime = end_time - start_time\n",
    "        runtime_list.append(runtime)\n",
    "\n",
    "        # Adversarial accuracy calculation\n",
    "        output_adversarial = art_net.predict(x_adversarial)\n",
    "        _, predicted_adversarial = torch.max(torch.tensor(output_adversarial).data, 1)\n",
    "\n",
    "        # Adversarial distance calculation: if no AE found, save epsilon as distance, otherwise save the distance\n",
    "        if int(predicted_adversarial.item()) == int(y.item()):\n",
    "            robust_predictions += 1\n",
    "            distance = epsilon\n",
    "            distance_list.append(distance)\n",
    "            if verbose:\n",
    "                print(f'Image {i}: No adversarial example found.')\n",
    "        else:\n",
    "            distance = torch.norm((x.cpu() - x_adversarial), p=float(norm))\n",
    "            robust_predictions += (round(distance.item(), 2) > epsilon) \n",
    "            attack_successes += (round(distance.item(), 2) <= epsilon) \n",
    "            distance_list.append(min(distance.item(), epsilon)) #appending epsilon if distance of adversarial example is higher\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Image {i}\\t\\tAdversarial_distance: {distance:.5f}\\t\\tRuntime: {runtime:5f} seconds')\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f'{i+1} images done. Current Adversarial Accuracy: {robust_predictions/(i+1)}%')\n",
    "\n",
    "    adversarial_accuracy = (robust_predictions / len(xtest)) * 100\n",
    "    attack_success_rate = (attack_successes / clean_correct) * 100\n",
    "    print(f'\\nAdversarial accuracy: {adversarial_accuracy}%\\n')\n",
    "\n",
    "    return distance_list, runtime_list, adversarial_accuracy, attack_success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 1  # 1, 2, np.inf\n",
    "max_iterations_fast_attacks = 20\n",
    "max_iterations_slow_attacks = 20\n",
    "eps_iter = 0.15\n",
    "epsilon = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "splitsize = 50      # full, int: splitsize\n",
    "xtest, ytest = load_dataset(dataset_split=splitsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the testset is: 92.000%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(net, xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t-------------------------- Processing Attack: acc_exp_attack --------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0464804abe4e7a9b976059f874a9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AccExp:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shao/elastic_net_adversarial_attack/adversarial_attack/acc_exp_attack.py:263: RuntimeWarning: invalid value encountered in log\n",
      "  x_val = np.where(abc>=15.0,np.log(abc)-np.log(np.log(abc))+np.log(np.log(abc))/np.log(abc), lambertw( np.exp(abc), k=0).real )/b-a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0: No adversarial example found.\n",
      "Image 0\t\tAdversarial_distance: 12.00000\t\tRuntime: 11.787620 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a6e14248964a8ca5ad5256931adb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AccExp:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1\t\tAdversarial_distance: 24.85469\t\tRuntime: 11.822661 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a277a8561d6f46d3a27d5648cda7313b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AccExp:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 2\t\tAdversarial_distance: 37.07571\t\tRuntime: 11.539268 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf805ea7a94840628cdb02150a6ad44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AccExp:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m results_dict[attack_type] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m-------------------------- Processing Attack: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattack_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m results_dict[attack_type][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madversarial_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m], results_dict[attack_type][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime\u001b[39m\u001b[38;5;124m\"\u001b[39m], results_dict[attack_type][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madversarial_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m] , results_dict[attack_type][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattack_success_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m calculation(\n\u001b[1;32m     23\u001b[0m                                                     art_net\u001b[38;5;241m=\u001b[39mart_net,\n\u001b[1;32m     24\u001b[0m                                                     fb_net\u001b[38;5;241m=\u001b[39mfb_net,\n\u001b[1;32m     25\u001b[0m                                                     net \u001b[38;5;241m=\u001b[39m net,\n\u001b[1;32m     26\u001b[0m                                                     xtest\u001b[38;5;241m=\u001b[39mxtest,\n\u001b[1;32m     27\u001b[0m                                                     ytest\u001b[38;5;241m=\u001b[39mytest,\n\u001b[1;32m     28\u001b[0m                                                     epsilon\u001b[38;5;241m=\u001b[39mepsilon,\n\u001b[1;32m     29\u001b[0m                                                     eps_iter\u001b[38;5;241m=\u001b[39meps_iter,\n\u001b[1;32m     30\u001b[0m                                                     norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[1;32m     31\u001b[0m                                                     max_iterations_fast_attacks\u001b[38;5;241m=\u001b[39mmax_iterations_fast_attacks,\n\u001b[1;32m     32\u001b[0m                                                     max_iterations_slow_attacks\u001b[38;5;241m=\u001b[39mmax_iterations_slow_attacks,\n\u001b[1;32m     33\u001b[0m                                                     attack_type\u001b[38;5;241m=\u001b[39mattack_type,\n\u001b[1;32m     34\u001b[0m                                                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m mean_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results_dict[attack_type][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madversarial_distance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMean adversarial distance for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattack_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with total runtime: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(results_dict[attack_type][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m .5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 55\u001b[0m, in \u001b[0;36mcalculation\u001b[0;34m(art_net, fb_net, net, xtest, ytest, epsilon, eps_iter, norm, max_iterations_slow_attacks, max_iterations_fast_attacks, attack_type, verbose)\u001b[0m\n\u001b[1;32m     53\u001b[0m     x_adversarial \u001b[38;5;241m=\u001b[39m x_adversarial\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:             \n\u001b[0;32m---> 55\u001b[0m     x_adversarial \u001b[38;5;241m=\u001b[39m attacker\u001b[38;5;241m.\u001b[39mgenerate(x\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     56\u001b[0m     x_adversarial \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x_adversarial)\n\u001b[1;32m     58\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/elastic_net_adversarial_attack/adversarial_attack/acc_exp_attack.py:126\u001b[0m, in \u001b[0;36mAccExpAttack.generate\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     x_batch \u001b[38;5;241m=\u001b[39m x_adv[batch_index_1:batch_index_2]\n\u001b[1;32m    125\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y[batch_index_1:batch_index_2]\n\u001b[0;32m--> 126\u001b[0m     x_adv[batch_index_1:batch_index_2] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_batch(x_batch, y_batch)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Apply clip\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mclip_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/elastic_net_adversarial_attack/adversarial_attack/acc_exp_attack.py:174\u001b[0m, in \u001b[0;36mAccExpAttack._generate_batch\u001b[0;34m(self, x_batch, y_batch)\u001b[0m\n\u001b[1;32m    166\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinary search step \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m (c_mean==\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    168\u001b[0m     bss,\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary_search_steps,\n\u001b[1;32m    170\u001b[0m     np\u001b[38;5;241m.\u001b[39mmean(c_current),\n\u001b[1;32m    171\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Run with 1 specific binary search step\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m best_dist, best_label, best_attack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_bss(x_batch, y_batch, c_current)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# Update best results so far\u001b[39;00m\n\u001b[1;32m    177\u001b[0m o_best_attack[best_dist \u001b[38;5;241m<\u001b[39m o_best_dist] \u001b[38;5;241m=\u001b[39m best_attack[best_dist \u001b[38;5;241m<\u001b[39m o_best_dist]\n",
      "File \u001b[0;32m~/elastic_net_adversarial_attack/adversarial_attack/acc_exp_attack.py:226\u001b[0m, in \u001b[0;36mAccExpAttack._generate_bss\u001b[0;34m(self, x_batch, y_batch, c_batch)\u001b[0m\n\u001b[1;32m    224\u001b[0m x_adv\u001b[38;5;241m=\u001b[39mx_0\u001b[38;5;241m+\u001b[39mdelta_y\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Adjust the best result\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m (logits, l1dist, l2dist, endist) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(x\u001b[38;5;241m=\u001b[39mx_batch, x_adv\u001b[38;5;241m=\u001b[39mx_adv\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_rule \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEN\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    229\u001b[0m     zip_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(endist, logits)\n",
      "File \u001b[0;32m~/elastic_net_adversarial_attack/adversarial_attack/acc_exp_attack.py:332\u001b[0m, in \u001b[0;36mAccExpAttack._loss\u001b[0;34m(self, x, x_adv)\u001b[0m\n\u001b[1;32m    330\u001b[0m l2dist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39msquare(x \u001b[38;5;241m-\u001b[39m x_adv)\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    331\u001b[0m endist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m*\u001b[39m l1dist \u001b[38;5;241m+\u001b[39m l2dist\n\u001b[0;32m--> 332\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray(x_adv, dtype\u001b[38;5;241m=\u001b[39mART_NUMPY_DTYPE), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), l1dist, l2dist, endist\n",
      "File \u001b[0;32m~/anaconda3/envs/art/lib/python3.12/site-packages/art/estimators/classification/classifier.py:75\u001b[0m, in \u001b[0;36mInputFilter.__init__.<locals>.make_replacement.<locals>.replacement_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     74\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(lst)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fdict[func_name](\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/art/lib/python3.12/site-packages/art/estimators/classification/pytorch.py:323\u001b[0m, in \u001b[0;36mPyTorchClassifier.predict\u001b[0;34m(self, x, batch_size, training_mode, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mdataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    322\u001b[0m results_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x_batch,) \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;66;03m# Move inputs to device\u001b[39;00m\n\u001b[1;32m    325\u001b[0m     x_batch \u001b[38;5;241m=\u001b[39m x_batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device)\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;66;03m# Run prediction\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/art/lib/python3.12/site-packages/torch/utils/data/dataloader.py:697\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/art/lib/python3.12/site-packages/torch/autograd/profiler.py:738\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39m_record_function_enter_new(\n\u001b[1;32m    734\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    735\u001b[0m     )\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any):\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks_on_exit:\n\u001b[1;32m    740\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attack_types = [#'fast_gradient_method', #bounded-full\n",
    "                #'projected_gradient_descent', #bounded-full\n",
    "                #'pgd_early_stopping', #not-bounded\n",
    "                #'auto_projected_gradient_descent', #bounded-full\n",
    "                #'deep_fool', #not-bounded\n",
    "                #'brendel_bethge', #bounded-min\n",
    "                #'carlini_wagner_l2', #not-bounded\n",
    "                #'elastic_net', #not-bounded\n",
    "                'exp_attack',\n",
    "                #'acc_exp_attack'\n",
    "                #'elastic_net_L1_rule', #not-bounded\n",
    "                #'elastic_net_L1_rule_higher_beta', #not-bounded\n",
    "                #'ART_AutoAttack', #bounded-full\n",
    "                #'original_AutoAttack', #bounded-full\n",
    "                ]\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for attack_type in attack_types:\n",
    "    results_dict[attack_type] = {}\n",
    "    print(f'\\t\\t-------------------------- Processing Attack: {attack_type} --------------------------\\n')\n",
    "    results_dict[attack_type][\"adversarial_distance\"], results_dict[attack_type][\"runtime\"], results_dict[attack_type][\"adversarial_accuracy\"] , results_dict[attack_type][\"attack_success_rate\"] = calculation(\n",
    "                                                        art_net=art_net,\n",
    "                                                        fb_net=fb_net,\n",
    "                                                        net = net,\n",
    "                                                        xtest=xtest,\n",
    "                                                        ytest=ytest,\n",
    "                                                        epsilon=epsilon,\n",
    "                                                        eps_iter=eps_iter,\n",
    "                                                        norm=norm,\n",
    "                                                        max_iterations_fast_attacks=max_iterations_fast_attacks,\n",
    "                                                        max_iterations_slow_attacks=max_iterations_slow_attacks,\n",
    "                                                        attack_type=attack_type,\n",
    "                                                        verbose=True)\n",
    "    \n",
    "    mean_value = np.mean([x for x in results_dict[attack_type][\"adversarial_distance\"] if x is not None])\n",
    "\n",
    "    print(f'\\nMean adversarial distance for {attack_type}: {mean_value:.5f} with total runtime: {sum(results_dict[attack_type][\"runtime\"]): .5f} seconds\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results to JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = f'./data/attack_comparison_{model_name}_L{norm}.json'\n",
    "\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(results_dict, f, indent=4)\n",
    "print(f'Evaluation results are saved under \"{json_file_path}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_types_with_distance = [\n",
    "                'brendel_bethge', #bounded-min\n",
    "                'pgd_early_stopping', #not-bounded\n",
    "                'deep_fool', #not-bounded\n",
    "                'carlini_wagner_l2', #not-bounded\n",
    "                'elastic_net', #not-bounded\n",
    "                'elastic_net_L1_rule', #not-bounded\n",
    "                'elastic_net_L1_rule_higher_beta', #not-bounded\n",
    "                'exp_attack', #not-bounded\n",
    "                ]\n",
    "\n",
    "selected_attack_types_with_distance = [a for a in attack_types if a in attack_types_with_distance]\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in selected_attack_types_with_distance:\n",
    "  plt.plot(list(range(len(xtest))), results_dict[attack_type]['adversarial_distance'], label=attack_type)\n",
    "plt.xlabel('Image ID')\n",
    "plt.ylabel('Distance')\n",
    "plt.title(f'L{norm} Distance')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.xticks(list(range(len(xtest))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.plot(list(range(len(xtest))), results_dict[attack_type]['runtime'], label=attack_type)\n",
    "plt.xlabel('Image ID')\n",
    "plt.ylabel('Runtime [seconds]')\n",
    "plt.title('Runtime per image')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.bar(attack_type, results_dict[attack_type]['adversarial_accuracy'], label=attack_type)\n",
    "plt.xlabel('Attacks')\n",
    "plt.ylabel('Adversarial accuracy [%]')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.title('Adversarial Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.bar(attack_type, results_dict[attack_type]['attack_success_rate'], label=attack_type)\n",
    "plt.xlabel('Attacks')\n",
    "plt.ylabel('Attack Success Rate [%]')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.title('Attack Success Rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for attack_type in attack_types:\n",
    "  plt.bar(attack_type, sum(results_dict[attack_type]['runtime'])/splitsize, label=attack_type)\n",
    "plt.xlabel('Attacks')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Runtime [seconds]')\n",
    "plt.title('Average Runtime per Image')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "art",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
